[["index.html", "Data Wrangling and Visualization Guide Preface", " Data Wrangling and Visualization Guide Max Ricciardelli 2023-07-28 Preface These modules are here to present a succinct guide to using R, RStudio, and R Markdown for data wrangling and visualization. This guide is meant for those who have little to no experience in programming. My purpose in designing these modules is to provide a brief yet clear guide to learning the basic theory of these tools and how to apply them in practice. Throughout this book, I will reference online resources that provide more in-depth discussion of the topics covered. The internet is full of helpful resources concerning R and RStudio. If you run into an issue, do not be hesitant to use forums such as stack overflow. Someone has most likely run into the same problem before. A simple Google search will often do the trick. Before starting this book, I recommend working through Professor Andy Field’s guide.1 I use his recommendations for reorganizing the windows in R Studio to promote better workflow. Most of the assignments you submit will be as a PDF output, making it important that you download LATEX, the software used to produce these outputs. The different versions of LATEX can be found here. As you are working, it can be very difficult to remember the finer points of R markdown’s syntax. RStudio has made a bunch of very helpful cheat sheets that provide examples of almost anything you might want to do.2 Those can be accessed through the help menu as demonstrated in the screenshot below: You are also able to pull up a list of markdown syntax within RStudio. This will appear in the help window of RStudio: Additionally, you can always use the search bar in the top rights of the help window to search for the documentation of any function. These are the packages needed for work in this book: here3 great package for referencing file names and paths leanr4 enables tutorials in RStudio tidyverse5 collection of integrated packages for data manipulation and visualization packages from tidyverse used in this book dplyr6 package for data wrangling ggplot27 package for data manipulation lubridate8 package for date time objects readr9 package for reading files tibble10 package for creating effective data frames forcats11 package for factor objects knitr12 tidy table output in both html and pdf gt13 used to easily generate professional table outputs from data frames tidycensus14 package for accessing US census data and estimates through their API nycflights1315 sample data set for practice using the data visualization (ggplot2) and wrangling (dplyr) packages readxl16 allow for reading excel files directly into a data frame ipumsr17 package for accessing IPUMS API gtrendsR18 package for accessing the Google trends API rvest19 package for web scraping Uncomment and run this code in your console to install all necessary packages for work in this book: #install.packages(&quot;tidyverse&quot;, here&quot;, &quot;learnr&quot;, &quot;tidyverse&quot;, &quot;knitr&quot;, &quot;tidycensus&quot;, &quot;nycflights13&quot;, &quot;readxl&quot;, &quot;ipumsr&quot;, &quot;gtrendsR&quot;, &quot;rvest&quot;) References "],["programming_basics.html", "1 R and Programming Basics 1.1 Projects 1.2 Code Chunks 1.3 Packages, Functions, File Structure, and File Paths 1.4 Objects, data, and types 1.5 Logical Operators 1.6 If Else Statements 1.7 For and While loops 1.8 Writing your own functions 1.9 Tutorials", " 1 R and Programming Basics In this chapter I will cover the basics of programming. Each programming language has its own intricacies, but the underlying concepts are often the same. I will explain how the basic concepts of programming are present in the syntax of R, offer tips on how to resolve stubborn issues, and suggest additional resources for exploring R and RStudio. 1.1 Projects R uses project files to save the state of your work space. When you make a new project it creates a folder that holds all of the relevant files for that project. You can hold all files of a type (e.g. figures or data) in a folder and then reference that folder, allowing for easy access and clear organization. RStudio saves the work space state into the project file (.Rproj). When you reopen that file, all the windows you had open will reappear exactly as they were. This is very useful for preserving your workflow. Projects are able to link multiple R markdown documents and other files around the same final project in a coherent way. This can be a wonderful way to take notes in class around examples of code. It is also very useful when working on an assignment with different sections. For example, in my work I often use separate R markdown documents for the data cleaning process and the data analysis and visualization process. By creating separate documents, I am able to run each section independently and then create a final document in another R markdown file that contains intentional elements from each stage. This is an example of a sample project I made to illustrate how to organize files, using the tips Andy Field recommends in his tutorial:20 The names of each folder or file must be easy to reference. To make sure that they are able to be referenced in your code, do not use capital letters or spaces, only lowercase letter and underscores. In computer science, this convention is called camel case. File names should be consistent and clear to anyone who looks at your project. 1.2 Code Chunks A code chunk is a section of code within a R markdown document. Each code chunk has settings to change how it interacts with the final document. By default, the code chunk will run the code and display both the code and output in the final document. When creating final products that generate professional output, often it will be best to change those settings by clicking the gear in the top left of the chunk. For visualizations, where the output is the only part you want in your final product, it is best to set the chunk to show output only. Otherwise, it is best in your final document to set the code to show nothing (run code), unless you are specifically talking about the code and need to reference it. To avoid having to set each code chunk individually, you can do your coding and preliminary drafting in a rough document and then create a clean final document that references files created and saved from the messy document. This allows you to have a more robust record of your process and create a more refined final submission. 1.3 Packages, Functions, File Structure, and File Paths Andy Field does a good job covering the basics of calling files and the value of the here()function in his tutorial.21 here() is a very useful tool in quickly referencing file names and folders without having to type out or copy and paste the name each time. 1.3.1 Packages and Functions Packages are collections of code snippets called functions, usually focused around a central idea or task. For example, the dplyr package is focused around data manipulation. A function can have parameters that are inputs required for functions to run. Parameters can be all sorts of objects or data types. They can be required or optional. Everything you need to know about a function is contained in its documentation, which can be found on the internet on the r documentation website or be accessed directly in RStudio by typing ?function() into the console as shown in the screenshot below. *note I reorganize my windows to put the console in the top right; usually it is in the bottom left window 1.3.2 Installing and Referencing Packages The code snippets below shows how to install a package, call it using the library() function, and then use a function within a package. I have the installation code commented out as I already have the package installed. To denote a comment within code you put # before the comment, telling R not to run anything after the #. Comments are very important for labeling what you are doing in your code so others can understand what you are trying to do. You only need to install a package once and it should be done in the console section instead of in a R markdown file or code chunk. Its important to use the exact syntax shown below. If you do not surround the name of the packages with quotation marks within the parentheses (either \" \", or ' ') it will not run. The double or single quotes indicates to R that the text inside is to be read as a string, not as code. The packages used in this book are outlined the end of the preface. # install.packages(&quot;here&quot;) library(here) ## here() starts at /Users/max/Desktop/wrangling_modules # this is another comment 1.3.3 Calling Functions The code chunk below demonstrates how to use the here() function to generate a file pathway to a file in your working directory. The working directory refers to the folder R pulls files from. The default setting for the working directory is your project folder. here() adds the text contained within the here function to the end of the working directory file path. If you do not want to load the package, as you only need to use it once when importing data, it can be written like this: here::here(). package::function() allows you to reference a function from a package without having to use library(package) to load in the package. Andy Field does a good job explaining the structure of file paths in the recommended sections from his tutorial.22 here(&#39;folder/file.ext&#39;) ## [1] &quot;/Users/max/Desktop/wrangling_modules/folder/file.ext&quot; 1.3.4 Changing the Working Directory The working directory can be changed by through setwd(file_path). This is useful when trying to access files that are not saved within the R project you are working on. The working directory is only changed for the code chunk it is used in and does not affect the suggested file path from here(). In the code chunk below I use setwd() to reference my desktop. setwd(&#39;/Users/max/Desktop&#39;) 1.4 Objects, data, and types As you are coding in R, you need to save things. To save something, use the assignment operator &lt;-. Saving something allows you to refer to it later. There are a few basic categories of individual data types: boolean booleans are either TRUE or FALSE numeric numeric values represent some sort of number e.g. num &lt;- 50 string a string of characters e.g. \"Hello!\" or 'Hello!' missing value designated as NA can be used in conjuntion with any of the above types, as it does not have an inherent type Any of these data types can be saved in a vector. A vector is a list of ordered individual elements. All the elements within a vector must be the same individual data type. 1.4.1 Mathematical Operators R has all the features of a calculator and can perform advanced mathematical operations through functions. Here is a list of all the mathematical operators and their symbols: + - addition - - subtraction * - multiplication / - division ^ - exponent These are some relevant mathematical functions in base R: log() - natural log cos() - cosine sin() - sine The round() function is useful for rounding numbers to integers. If you specify the number of digits with the digits = parameters you can limit number of digits saved. If you are trying to do something mathematical there is almost certainly already a function for it. Don’t be afraid to look it up. This code chunk is an example of how to save each data type and demonstrates the syntax for basic mathematical operations: boolean &lt;- TRUE # boolean data type string &lt;- &quot;Hello!&quot; string_2 &lt;- &#39;Hello&#39; value &lt;- 10 # numeric data type # spaces aren&#39;t necessary but allow for easier reading value_2 &lt;- value * 2 # multiplication operator value_2 # by printing a variable name on a line of code, R will display it ## [1] 20 (value_3 &lt;- value / 10) # division operator ## [1] 1 # if you put parentheses around something when you do it, it prints it as well value_4 &lt;- value + (20.5678 - 10.45) # addition and subtraction operators as well as the order of operations value_5 &lt;- cos(value_3) # example of using a function # this is an example of a function included in &quot;Base R&quot;, # meaning you do not have to reference a package using library() to use it value_4 ## [1] 20.1178 round(value_4) ## [1] 20 round(value_4, digits = 2) ## [1] 20.12 1.4.2 Objects Elements can be combined using the c()function to create vectors: values &lt;- c(10, 23, 45, 36, 78, 97, 11, 8, 94) strings &lt;- c(&#39;apple&#39;, &#39;berry&#39;, &#39;camel&#39;, &quot;driver&quot;, &quot;email&quot;) booleans &lt;- c(TRUE, FALSE, TRUE, TRUE, FALSE, FALSE, FALSE) (mean &lt;- mean(values)) # this shows the use of a function on a set of numeric variables ## [1] 44.66667 Everything you save will be stored in the environment window of RStudio and can be viewed by clicking on it: Objects are a collection of any of these value types or another data structure. They usually have a specified organization and can be integrated with different packages. Different data types will be discussed further in Chapter 2. 1.5 Logical Operators The logical operators are useful for comparing boolean and numeric variables. These operators can be used in conjunction with loops and if/else statements. 1.5.1 Boolean Operators Boolean operators can be used to compare boolean values (TRUE or FALSE) and sometimes numeric values. These operators always return a boolean result. &amp; - and both sides of &amp; must evaluate as TRUE to return true, otherwise the statement returns FALSE only evaluates booleans TRUE &amp; FALSE ## [1] FALSE TRUE &amp; TRUE ## [1] TRUE FALSE &amp; FALSE ## [1] FALSE | - or if either side of | is TRUE, this statement returns TRUE only evaluates booleans TRUE | FALSE ## [1] TRUE TRUE | TRUE ## [1] TRUE FALSE | FALSE ## [1] FALSE == - equal returns TRUE if both side of the statement are equivalent, returns FALSE if they are not can also be used with numeric variables as well as boolean note: in a logical expression syntax requires two equal signs TRUE == TRUE ## [1] TRUE FALSE == TRUE ## [1] FALSE 50 == 50 ## [1] TRUE 51 == 50 ## [1] FALSE != - not equal can also be used with numeric variables as well as boolean if the variables are not equal, this statement returns TRUE; if they are equal, it returns FALSE TRUE != TRUE ## [1] FALSE FALSE != TRUE ## [1] TRUE 50 != 50 ## [1] FALSE 51 != 50 ## [1] TRUE 1.5.2 Numeric Operators These numeric logical operators return (output) a boolean result: &gt; - greater than 50 &gt; 51 ## [1] FALSE 51 &gt; 50 ## [1] TRUE 0 &gt; 0 ## [1] FALSE &gt;= - greater than or equal to 50 &gt;= 51 ## [1] FALSE 51 &gt;= 50 ## [1] TRUE 0 &gt;= 0 ## [1] TRUE &lt; - less than 50 &lt; 51 ## [1] TRUE 51 &lt; 50 ## [1] FALSE 0 &lt; 0 ## [1] FALSE &lt;= - less than or equal to # this can be done with saved values as well a &lt;- 50 b &lt;- 51 a &lt;= b ## [1] TRUE b &lt;= a ## [1] FALSE a &lt;= a ## [1] TRUE NA represents a missing value and does not have a type like the examples above. This is very useful for representing missing values in a way that R recognizes, but can lead to errors if used with certain functions. 1.6 If Else Statements If else statements make the execution of code conditional on a boolean statement. An if statement only executes the code inside the curly brackets ({) if the conditional statement evaluates to TRUE. If the conditional statement evaluates to FALSE, it executes the code in the else statement. An else statement is not required. When using the if statement the basic structure is as follows: if(boolean statement){code to execute}. It is best to space out the bracket and parentheses syntax over multiple lines as demonstrated in the example below. The syntax must precisely be followed otherwise the code will break or run in an unintentional way. # Lets use the same variables as above a &lt;- 50 b &lt;- 51 # a &lt;= b evaluates to TRUE if (a &lt;= b){ print(&quot;TRUE&quot;) } ## [1] &quot;TRUE&quot; # a &gt;= b evaluates to FALSE if (a &gt;= b){ print(&quot;TRUE&quot;) } #when there is no else statement and the if statement evaluates to FALSE, nothing happens # if / else statement example if (b &lt;= a){ print(&quot;TRUE&quot;) } else{ print(&quot;FALSE&quot;) } ## [1] &quot;FALSE&quot; You can add an else statement after the second curly bracket of the if statement in the same line with its own set of curly brackets. The code within the brackets of the else statement only runs if the above if statement evaluates to false. An example of this is shown in the chunk above and the general form is shown here: if(boolean){code} else{other code} 1.7 For and While loops For and while loops are useful code structures that allow you to repeat sections of code either a set number of times or until the desired result is achieved. Before getting into the specifics of loops, we must discuss indexing in R. Indexing is how a programming language counts. Programming languages either start indexing (counting) at 0 or 1. R indexes starting at 1 and going to the final number of the count. This is demonstrated in the for loops section below. 1.7.1 For Loops For loops run the code within the loop a set number of times for (x in 1:5){ # this loop increases by one each time it runs until x = 5 print(x) # what you want the loop to do } # this loop prints the current value of x ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 ## [1] 5 You can also use for loops to iterate over the items within an object. The code chunk below demonstrates this using a vector of integers. obj &lt;- c(1,2,3,4,5,6,7,8,9,10) for (y in obj){ # each time this loop runs y represents the next item in the vector # this loop runs the number of items in the vector (often denoted n) y &lt;- y + 10 # this statement adds 10 the current value of y print(y) # this statement prints y } ## [1] 11 ## [1] 12 ## [1] 13 ## [1] 14 ## [1] 15 ## [1] 16 ## [1] 17 ## [1] 18 ## [1] 19 ## [1] 20 1.7.2 While Loops While loops run until the specified parameter is satisfied. You must be careful with while loops, because if the loop parameter is never satisfied in your code the computer will run the loop forever and your program will break. The code chunk below illustrates how to use while loops. num &lt;- 0 while(num &lt;= 10){ # why does this loop print from 1 to 11 instead of 0 to 10? num &lt;- num + 1 # examine the code of the loop line by line as the computer looks at it for debuging print(num) # print statements are a useful tool in debuging # they help determine where your code breaks } ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 ## [1] 5 ## [1] 6 ## [1] 7 ## [1] 8 ## [1] 9 ## [1] 10 ## [1] 11 1.8 Writing your own functions Writing your own functions is valuable when you are writing code to do the same thing multiple times. By generalizing the variables of what you are trying to do as parameters in a function, the entire task becomes very easy to replicate. Writing functions also increases your understanding of the processes you are trying to code. The add_ten function, shown below, demonstrates how to use a parameter and optional parameter to add ten to a numeric variable and then raise it to the power of the optional variable if the optional parameter is specified. # write our own function add_ten &lt;- function(parameter, optional = 0){ # the optional parameter is zero if not specified new &lt;- as.numeric(parameter) + 10 # add ten to the numeric parameter # the as.numeric function here solves a type error when knitting if (optional != 0){ # if the optional parameter does not equal 0 new &lt;- new^optional # raise new to the power of the option parameter if included } return(new) # the return statement ends the function and whats inside the parentheses is the result of the function } # if you save a function, it saves what the function returns (result &lt;- add_ten(10)) # call and run the written function above ## [1] 20 # this works without the optional parameter add_ten(20, optional = 2) # if you use an optional parameter you must set it equal to the name of the parameter ## [1] 900 add_ten(&#39;abc&#39;) # this causes a missing value because you cannot add 10 to a non-numeric variable ## Warning in add_ten(&quot;abc&quot;): NAs introduced by coercion ## [1] NA 1.9 Tutorials Installing the learnr package will enable tutorials within R studio for a variety of useful things.23 You can access this in the environment window in RStudio. If you run into any problems using a function, the first step is to search for the documentation for that function. The documentation will outline all of the required parameters, optional parameters, and examples for how to use the function. References "],["data.html", "2 Data 2.1 Data Frames 2.2 Importing Data 2.3 Saving Files 2.4 Cleaning Data and the Tidyverse 2.5 Data Sources 2.6 Conclusion", " 2 Data This chapter explains how to deal with different types of data within R, as well as how to clean, manipulate, and save data. When we are dealing with data we will be using the object of a data frame to save the data within the temporary memory of R itself (shown in the environment). This chapter uses the packages dplyr, forcats, tibble, readr, and lubridate, which are all contained within the tidyverse. Additional packages outside of the tidyverse and mentioned as they are used. The installation and calling of the tidyverse is demonstrated in the code chunk below: library(tidyverse) ## ── Attaching core tidyverse packages ──────────────────────────────────────────────────────── tidyverse 2.0.0 ── ## ✔ dplyr 1.1.1 ✔ readr 2.1.4 ## ✔ forcats 1.0.0 ✔ stringr 1.5.0 ## ✔ ggplot2 3.4.2 ✔ tibble 3.2.1 ## ✔ lubridate 1.9.2 ✔ tidyr 1.3.0 ## ✔ purrr 1.0.1 ## ── Conflicts ────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors The output from calling the tidyverse shows all of the different packages it loads into R at once and their most recent version. The core packages comprise a powerful suite of tools for importing, wrangling, and visualizing data. 2.1 Data Frames Within R itself, a typed data frame can be created in two different ways: using the tibble() or tribble() functions. Both functions do exactly the same thing using different syntax. The tibble() function uses the format row = c(), row2 = c(). The tribble() function uses a vertical format, with ~ denoting the row names. An example of how to the tibble() function is given in the code chunk below: # the tibble function joins either manually set or referenced vectors of the same length into a data frame (data_frame &lt;- tibble(row = c(1,2,3,4,5,6,7,8,9,10), # row_name = vector(length 10) color = c(&#39;red&#39;, &#39;blue&#39;, &#39;yellow&#39;, &#39;green&#39;, &#39;purple&#39;, &#39;orange&#39;, &#39;magenta&#39;, &#39;red&#39;, &#39;purple&#39;, &#39;orange&#39;), category = c(&#39;warm&#39;, &#39;cold&#39;, &#39;warm&#39;, &#39;cold&#39;, &#39;cold&#39;, &#39;warm&#39;, &#39;warm&#39;, &#39;warm&#39;, &#39;cold&#39;, &#39;warm&#39;), boolean = c(TRUE, TRUE, FALSE, TRUE, FALSE, TRUE, FALSE, FALSE, TRUE, TRUE))) ## # A tibble: 10 × 4 ## row color category boolean ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt; ## 1 1 red warm TRUE ## 2 2 blue cold TRUE ## 3 3 yellow warm FALSE ## 4 4 green cold TRUE ## 5 5 purple cold FALSE ## 6 6 orange warm TRUE ## 7 7 magenta warm FALSE ## 8 8 red warm FALSE ## 9 9 purple cold TRUE ## 10 10 orange warm TRUE Underneath the row name in &lt;&gt; is the data type of the column. &lt;dbl&gt; refers to double, &lt;chr&gt; refers to character, and &lt;lgl&gt; refers to logical. &lt;dbl&gt; is the standard data type for numbers and &lt;chr&gt; is the standard data type for text in R. &lt;lgl&gt; refers to a TRUE or FALSE value, usually called a Boolean in computer science. &lt;int&gt;, referring to integers, is another common data type. The rows must be the same length for the tibble() or tribble() function to run. Each row here has a length of 10. The function is surrounded in parentheses so the output prints. The code chunk below demonstrates how to use the tribble() function: # the tribble identifies the column name on the first line with the ~ symbol (data_frame2 &lt;- tribble(~row, ~row2, 1,2, #subsequent rows going across are inputted underneath 3,4, 5,6, 7,8 )) # this provides an alternative method to hand entering these ## # A tibble: 4 × 2 ## row row2 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 ## 2 3 4 ## 3 5 6 ## 4 7 8 It is important to make sure each column is the intended data type. Functions (especially mathematical ones) often require a certain data type as an input. 2.1.1 Date Time Objects There is a special data type for dates and times available through the lubridate package. This package is automatically included in the tidyverse. There are three different data types associated with dates/times: a date data type signifying the day, month, and year (&lt;date&gt;); a time data type signifying the time within a day (&lt;time&gt;); and a date time which includes both (&lt;dttm&gt;). The code chunk below demonstrates how to use the make_datetime() function to create date time objects. Using this data type ensures that graphs over time are produced properly using ggplot2. make_datetime(year = 2020, month = 11, day = 25) ## [1] &quot;2020-11-25 UTC&quot; Often, one of the hardest parts of working with a new data set is correctly changing however they keep the date/time into a date time object. The lubridate package is able to create these objects with a variety of input formats, making this process much easier. The code chunk below demonstrates different methods of creating &lt;dttm&gt; objects. This is done through the parse_date_time(x, orders) function. The orders argument tells the function what format your date is in. A full list of different possible orders is available in the documentation for the function. parse_date_time(&#39;2017-01-02&#39;, orders = &quot;ymd&quot;) #year month day orders ## [1] &quot;2017-01-02 UTC&quot; parse_date_time(&quot;01/02/2017&quot;, orders = &quot;mdy&quot;, tz = &quot;UTC&quot;) # month day year orders ## [1] &quot;2017-01-02 UTC&quot; # can specify a time zone as well parse_date_time(&quot;2 Jan 2017 10:00:00 PM&quot;, orders = &quot;dmy_HMS&quot;) #year month day_hour minute second ## [1] &quot;2017-01-02 10:00:00 UTC&quot; # this function can also read full text and abbreviations One of the other really useful parts of lubridate date/time objects is the ability to refer to different components of a date time object. If you have a complete date time object, year(date_time) returns the year, month(date_time) returns the month, mday(date_time) returns the day of the month, wday(date_time) returns the day of the week, and the same for hour(date_time), minute(date_time), and second(date_time). This will be used further in Chapter 3 in conjunction with visualizing time series. (today &lt;- now()) ## [1] &quot;2023-07-28 12:10:51 EDT&quot; year(today) ## [1] 2023 month(today) ## [1] 7 mday(today) ## [1] 28 wday(today) ## [1] 6 wday(today, label=TRUE) # this returns a factor ordering the days of the week properly ## [1] Fri ## Levels: Sun &lt; Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat hour(today) ## [1] 12 minute(today) ## [1] 10 second(today) ## [1] 51.14917 For more in-depth information and examples concerning lubridate refer to the Dates and Times chapter of R for Data Science.24 Additionally, looking at the documentation of the package is always helpful. 2.1.2 Factors Factors are a specialized data type meant to deal with ordered categorical variables. Factors are available as part of the forcats package. This data type best applies to a character variable that has a specified order, such as months in a year.25 To convert a simple string variable into a factor you must use the factor() function. The code chunk below shows an example of converting a character vector to a factor. The difference can be seen when the factor and character vectors are sorted. Factors are most useful within data frames. They give R a roadmap of how to value categorical variables properly, making graphing, filtering, and general analysis easier. mon &lt;- c(&quot;Mar&quot;, &quot;Apr&quot;, &quot;Dec&quot;, &quot;Feb&quot;, &quot;Nov&quot;, &quot;Jun&quot;, &quot;Aug&quot;, &quot;Jan&quot;, &quot;Oct&quot;, &quot;May&quot;, &quot;Jul&quot;, &quot;Sep&quot;) factor &lt;- factor(mon, levels = c(&quot;Jan&quot;, &quot;Feb&quot;, &quot;Mar&quot;, &quot;Apr&quot;, &quot;May&quot;, &quot;Jun&quot;, &quot;Jul&quot;, &quot;Aug&quot;, &quot;Sep&quot;, &quot;Oct&quot;, &quot;Nov&quot;, &quot;Dec&quot;)) sort(mon) # this output does not have any ordering so it does not sort properly ## [1] &quot;Apr&quot; &quot;Aug&quot; &quot;Dec&quot; &quot;Feb&quot; &quot;Jan&quot; &quot;Jul&quot; &quot;Jun&quot; &quot;Mar&quot; &quot;May&quot; &quot;Nov&quot; &quot;Oct&quot; &quot;Sep&quot; sort(factor) # this output has the ordering for the months saved in the levels parameter ## [1] Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec ## Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec For a more in-depth explanation of factors, refer to Chapter 15: Factors of R for Data Science.26 2.1.3 Subsetting Data Frames When working with data frames, such as data_frame2 above, you may not want to reference the entire data frame. Often it is useful to just reference a column or element from a data frame. There are two main ways to do this. A column can be referenced by the name of the column using the following format: data_frame$col_name. The result is a vector containing the elements in the specified column. This is demonstrated in the code chunk below using data_frame2. data_frame2 ## # A tibble: 4 × 2 ## row row2 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 ## 2 3 4 ## 3 5 6 ## 4 7 8 data_frame2$row ## [1] 1 3 5 7 While that is the simplest way to reference a column, it is also possible to reference a column or element within a column through its position. This can be done through the following general syntax: data_frame[[col_index]][[row_index]] or data_frame[col_index, row_index]. The syntax with the double brackets returns the element in its own data type, stripping it of its status as a data frame. Using the second syntax keeps its format as a tibble. The code chunk below demonstrates how to use both with data_frame2. data_frame2 ## # A tibble: 4 × 2 ## row row2 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 ## 2 3 4 ## 3 5 6 ## 4 7 8 data_frame2[[1]] ## [1] 1 3 5 7 data_frame2[[1]][[1]] ## [1] 1 data_frame2[1] ## # A tibble: 4 × 1 ## row ## &lt;dbl&gt; ## 1 1 ## 2 3 ## 3 5 ## 4 7 data_frame2[1,1] ## # A tibble: 1 × 1 ## row ## &lt;dbl&gt; ## 1 1 2.1.4 Displaying Data Frames in Markdown The default format for displaying data frames in a final output is very limited. As seen in the example below, it prints it in machine output and does not display all rows if the data frame is too big. data_frame ## # A tibble: 10 × 4 ## row color category boolean ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt; ## 1 1 red warm TRUE ## 2 2 blue cold TRUE ## 3 3 yellow warm FALSE ## 4 4 green cold TRUE ## 5 5 purple cold FALSE ## 6 6 orange warm TRUE ## 7 7 magenta warm FALSE ## 8 8 red warm FALSE ## 9 9 purple cold TRUE ## 10 10 orange warm TRUE To create a more professional output for data frames, we use the gt() function from the gt package. library(gt) gt(data_frame) #ttnmruxvok table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #ttnmruxvok thead, #ttnmruxvok tbody, #ttnmruxvok tfoot, #ttnmruxvok tr, #ttnmruxvok td, #ttnmruxvok th { border-style: none; } #ttnmruxvok p { margin: 0; padding: 0; } #ttnmruxvok .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #ttnmruxvok .gt_caption { padding-top: 4px; padding-bottom: 4px; } #ttnmruxvok .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #ttnmruxvok .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #ttnmruxvok .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #ttnmruxvok .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #ttnmruxvok .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #ttnmruxvok .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #ttnmruxvok .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #ttnmruxvok .gt_column_spanner_outer:first-child { padding-left: 0; } #ttnmruxvok .gt_column_spanner_outer:last-child { padding-right: 0; } #ttnmruxvok .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #ttnmruxvok .gt_spanner_row { border-bottom-style: hidden; } #ttnmruxvok .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #ttnmruxvok .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #ttnmruxvok .gt_from_md > :first-child { margin-top: 0; } #ttnmruxvok .gt_from_md > :last-child { margin-bottom: 0; } #ttnmruxvok .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #ttnmruxvok .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #ttnmruxvok .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #ttnmruxvok .gt_row_group_first td { border-top-width: 2px; } #ttnmruxvok .gt_row_group_first th { border-top-width: 2px; } #ttnmruxvok .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #ttnmruxvok .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #ttnmruxvok .gt_first_summary_row.thick { border-top-width: 2px; } #ttnmruxvok .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #ttnmruxvok .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #ttnmruxvok .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #ttnmruxvok .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #ttnmruxvok .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #ttnmruxvok .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #ttnmruxvok .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #ttnmruxvok .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #ttnmruxvok .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #ttnmruxvok .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #ttnmruxvok .gt_left { text-align: left; } #ttnmruxvok .gt_center { text-align: center; } #ttnmruxvok .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #ttnmruxvok .gt_font_normal { font-weight: normal; } #ttnmruxvok .gt_font_bold { font-weight: bold; } #ttnmruxvok .gt_font_italic { font-style: italic; } #ttnmruxvok .gt_super { font-size: 65%; } #ttnmruxvok .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #ttnmruxvok .gt_asterisk { font-size: 100%; vertical-align: 0; } #ttnmruxvok .gt_indent_1 { text-indent: 5px; } #ttnmruxvok .gt_indent_2 { text-indent: 10px; } #ttnmruxvok .gt_indent_3 { text-indent: 15px; } #ttnmruxvok .gt_indent_4 { text-indent: 20px; } #ttnmruxvok .gt_indent_5 { text-indent: 25px; } row color category boolean 1 red warm TRUE 2 blue cold TRUE 3 yellow warm FALSE 4 green cold TRUE 5 purple cold FALSE 6 orange warm TRUE 7 magenta warm FALSE 8 red warm FALSE 9 purple cold TRUE 10 orange warm TRUE The output is much more visually appealing and highly customizable. For example, the tab_header() function allows you to add a title and subtitle, as demonstrated below. gt(data_frame) |&gt; tab_header(title = &quot;Data Title&quot;, subtitle = &quot;More Information&quot;) # refer to piping operators #gjzhbcqsuw table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #gjzhbcqsuw thead, #gjzhbcqsuw tbody, #gjzhbcqsuw tfoot, #gjzhbcqsuw tr, #gjzhbcqsuw td, #gjzhbcqsuw th { border-style: none; } #gjzhbcqsuw p { margin: 0; padding: 0; } #gjzhbcqsuw .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #gjzhbcqsuw .gt_caption { padding-top: 4px; padding-bottom: 4px; } #gjzhbcqsuw .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #gjzhbcqsuw .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #gjzhbcqsuw .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #gjzhbcqsuw .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #gjzhbcqsuw .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #gjzhbcqsuw .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #gjzhbcqsuw .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #gjzhbcqsuw .gt_column_spanner_outer:first-child { padding-left: 0; } #gjzhbcqsuw .gt_column_spanner_outer:last-child { padding-right: 0; } #gjzhbcqsuw .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #gjzhbcqsuw .gt_spanner_row { border-bottom-style: hidden; } #gjzhbcqsuw .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #gjzhbcqsuw .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #gjzhbcqsuw .gt_from_md > :first-child { margin-top: 0; } #gjzhbcqsuw .gt_from_md > :last-child { margin-bottom: 0; } #gjzhbcqsuw .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #gjzhbcqsuw .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #gjzhbcqsuw .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #gjzhbcqsuw .gt_row_group_first td { border-top-width: 2px; } #gjzhbcqsuw .gt_row_group_first th { border-top-width: 2px; } #gjzhbcqsuw .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #gjzhbcqsuw .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #gjzhbcqsuw .gt_first_summary_row.thick { border-top-width: 2px; } #gjzhbcqsuw .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #gjzhbcqsuw .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #gjzhbcqsuw .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #gjzhbcqsuw .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #gjzhbcqsuw .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #gjzhbcqsuw .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #gjzhbcqsuw .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #gjzhbcqsuw .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #gjzhbcqsuw .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #gjzhbcqsuw .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #gjzhbcqsuw .gt_left { text-align: left; } #gjzhbcqsuw .gt_center { text-align: center; } #gjzhbcqsuw .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #gjzhbcqsuw .gt_font_normal { font-weight: normal; } #gjzhbcqsuw .gt_font_bold { font-weight: bold; } #gjzhbcqsuw .gt_font_italic { font-style: italic; } #gjzhbcqsuw .gt_super { font-size: 65%; } #gjzhbcqsuw .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #gjzhbcqsuw .gt_asterisk { font-size: 100%; vertical-align: 0; } #gjzhbcqsuw .gt_indent_1 { text-indent: 5px; } #gjzhbcqsuw .gt_indent_2 { text-indent: 10px; } #gjzhbcqsuw .gt_indent_3 { text-indent: 15px; } #gjzhbcqsuw .gt_indent_4 { text-indent: 20px; } #gjzhbcqsuw .gt_indent_5 { text-indent: 25px; } Data Title More Information row color category boolean 1 red warm TRUE 2 blue cold TRUE 3 yellow warm FALSE 4 green cold TRUE 5 purple cold FALSE 6 orange warm TRUE 7 magenta warm FALSE 8 red warm FALSE 9 purple cold TRUE 10 orange warm TRUE For more information on how to further customize tables using the functions available in gt, refer to the documentation here. This package is structured similarly to ggplot2, so I recommend reading Chapter 3 and then exploring the customization options this package has to offer. 2.1.5 Reference Saved Values in Markdown When creating a markdown document for final submission, you will have to submit statistics you generated through your analysis from saved data frames and discuss them within the text of your R markdown document. To avoid errors with copying numbers, I recommend referencing the saved values directly so R markdown exactly replicates them without error. This can be done through the syntax “r value_name” surrounded by backwards apostrophes. It is also possible to run functions within inline code: “r round(value_name, digits = 5)”. Refer to the bottom left of the first page of the R markdown cheat sheet for further explanation and examples. 2.2 Importing Data Importing data is an important skill. Data comes in a variety of formats which you must transfer into a data frame format to use with R. One option is to hand-type the data into the tibble or tribble function, but this is very time consuming. It is only easiest to use these functions with small data sets or a data frame you want to display as a table. 2.2.1 .csv Files Most often, data you encounter will be available in the .csv format (comma-separated-values). The readr package in the tidyverse provides the function, read_csv() for reading .csv files into a data frame. An example of how to use the read_csv() function is given in the chunk below: (data &lt;- read_csv(here(&quot;sample.csv&quot;))) ## Rows: 156 Columns: 2 ## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (1): Date ## dbl (1): Sales ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. ## # A tibble: 156 × 2 ## Date Sales ## &lt;chr&gt; &lt;dbl&gt; ## 1 Jan-92 1519 ## 2 Feb-92 1551 ## 3 Mar-92 1606 ## 4 Apr-92 1686 ## 5 May-92 1834 ## 6 Jun-92 1786 ## 7 Jul-92 1924 ## 8 Aug-92 1874 ## 9 Sep-92 1781 ## 10 Oct-92 1894 ## # ℹ 146 more rows # this reads a csv detailing monthly liquor sales data The sample.csv file is from Introduction to Time Series Analysis and Forecasting.27 2.2.2 Microsoft Excel Files Excel has changed the way they save their files over time, leading to a variety of formats for excel files (e.g. .xls, .xlsx). Excel files can always be saved as .csv files within excel and then read as a .csv file into R. If you want to directly read the excel file, the readxl package offers the ability to read an excel file directly into a data frame through the read_excel(file_name) function. This function can read almost any form of excel file, regardless of what generation the file type is. The code chunk below shows an example of how to do this. Note: to just use the file name the file must be in the current working directory (by default this is the project folder). library(readxl) read_excel(&quot;sample.xlsx&quot;) ## # A tibble: 156 × 2 ## Date Sales ## &lt;dttm&gt; &lt;dbl&gt; ## 1 1992-01-01 00:00:00 1519 ## 2 1992-02-01 00:00:00 1551 ## 3 1992-03-01 00:00:00 1606 ## 4 1992-04-01 00:00:00 1686 ## 5 1992-05-01 00:00:00 1834 ## 6 1992-06-01 00:00:00 1786 ## 7 1992-07-01 00:00:00 1924 ## 8 1992-08-01 00:00:00 1874 ## 9 1992-09-01 00:00:00 1781 ## 10 1992-10-01 00:00:00 1894 ## # ℹ 146 more rows If the excel file has multiple sheets, the sheet = parameter allows you to select the sheet by setting it equal to the name of the sheet (make sure to put the name in quotes so it is a string). If the excel file has blank lines at the beginning of the file you can use the skip = parameter to skip lines before it starts to read it. This is often necessary to ensure the .csv file correctly reads into a data frame. Excel has a very useful feature where it can read tables from pictures or screenshots of textbooks. This feature is found in the data tab of the top bar of excel and identified in the screenshot below. Simply select the file of a picture of the table and excel will try to import it. It isn’t perfect but often get most of it right. Always check the data for errors when using this, it still saves a ton of time. 2.2.3 RDS Files .RDS files are meant for use in R and are a good way to save and read data frames. They quickly load into R and are the format I use to save my files when I call them in a separate R markdown document. The read_rds() function reads existing RDS files into a data frame. 2.2.4 Conclusion Almost any data you encounter will be in either one of these three formats or able to be converted into one of these formats using methods discussed above. Getting a data file into a data frame is the first step in analyzing data and can sometimes be the most tedious if you are not able to troubleshoot the process effectively. Always check you data! 2.3 Saving Files Saving data frames allows you to save a snapshot of the data as you are going through your analysis. This can be useful after cleaning data. Often you will not need all the data in a data set or will have to alter the data. In the next section, I discuss what clean data is and how to clean your data using the tools of the tidyverse. It is still important to preserve the original data as you received it for reference later on and to prevent deletion of data that you are unable to recover. By having the original file saved, you are always able to go back and retrace your steps from the original formatting to the clean data. 2.3.1 Saving Data Frames Saving data frames can be very useful to reference your data set in the desired format, as well as for saving tables for display in your final document. I recommend saving data frames as RDS files, as they are the easiest for R to quickly read and allow you to display the results in whatever format you wish. In the code chunk below, I create a sample data frame called object and then use the saveRDS() function to save the file. # This creates a sample data frame to save as an RDS file object &lt;- tibble( a = c(1,2,3,4,5), b = c(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;) ) saveRDS(object, file = &quot;file_name.rds&quot;) # the first parameter is the object you want to save # in the file name it is important to end it with .rds so the computer knows what type of file it is To reload these files into R, or call them in another document, use the readRDS() as shown below: readRDS(&quot;file_name.rds&quot;) ## # A tibble: 5 × 2 ## a b ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 a ## 2 2 b ## 3 3 c ## 4 4 d ## 5 5 e 2.3.2 Saving Other File Types There are a variety of objects you may want to save in your code for later reference, either in a written work or another document. Saving visualizations as .png files will be covered in Chapter 3. For other types of objects that you may want to save, look on the internet for the best file type and function to use to save them. Always check that the saved file is as you intended it to be and that it can be read into the format you desire. 2.4 Cleaning Data and the Tidyverse What is clean data? For data to be clean there must be a clear pattern of organization to how the data is stored. This concept is also commonly referred to as tidy data. There are three general rules for making a data set tidy:28 Each variable must have its own column Each observation must have its own row Each value must have its own cell Table 1, shown below, is an example of a tidy data set. Each observation (pertaining to a country and a year) has its own row. Additionally, each variable has its own column. This table is included in the tidyverse as an example and used in R for Data Science.29 table1 ## # A tibble: 6 × 4 ## country year cases population ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583 Often, data when you receive it will not be in this format. The first step after successfully importing data is to clean it. The tidyverse offers functions that allow you to rearrange data frames into a format better suited for analysis and plotting. I will go through several examples of different common problems with data, and what functions are best to fix them. 2.4.1 Pivoting Data First, we will discuss the two functions used for pivoting data. The code chunk below shows a sample data frame that has multiple issues. Instead of having a column for each variable, the variable “type” indicates the kind of value in that row. Columns 3 and 4, which both contain doubles, indicate the year of the values in those columns. These are examples of common problems with data organization. sample_table ## # A tibble: 6 × 4 ## type country `1999` `2000` ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 population Afghanistan 19987071 20595360 ## 2 cases Afghanistan 745 2666 ## 3 population Brazil 172006362 174594898 ## 4 cases Brazil 37737 80488 ## 5 population China 1272915272 1280428583 ## 6 cases China 212258 213766 These two functions in dplyr each solve different problems: pivot_longer() this adds rows making the data frame longer this corrects the issue with the columns pertaining to the year of the corresponding value parameters: pivot_longer(data, cols, names_to = \"\", values_to = \"\") data: data frame to pivot cols: columns to pivot names_to: name of new column containing the column names of the pivoted columns values_to: name of new column containing the values of the pivoted columns (longer_table &lt;- pivot_longer(data = sample_table, cols = c(`1999`, `2000`), names_to = &quot;year&quot;, values_to = &quot;value&quot;)) ## # A tibble: 12 × 4 ## type country year value ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 population Afghanistan 1999 19987071 ## 2 population Afghanistan 2000 20595360 ## 3 cases Afghanistan 1999 745 ## 4 cases Afghanistan 2000 2666 ## 5 population Brazil 1999 172006362 ## 6 population Brazil 2000 174594898 ## 7 cases Brazil 1999 37737 ## 8 cases Brazil 2000 80488 ## 9 population China 1999 1272915272 ## 10 population China 2000 1280428583 ## 11 cases China 1999 212258 ## 12 cases China 2000 213766 # the data = and cols = are not necessary as they are required parameters pivot_wider() this adds columns making the data frame wider this corrects the issue that each variable does not have its own column parameters: pivot_wider(data, names from = \"\", values_from = \"\") data: data frame to pivot names_from: column whose values are the names of the new columns values_from: column whose values are the values of the new columns # this pivots the data frame after the longer pivot above pivot_wider(longer_table, names_from = type, values_from = value ) ## # A tibble: 6 × 4 ## country year population cases ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanistan 1999 19987071 745 ## 2 Afghanistan 2000 20595360 2666 ## 3 Brazil 1999 172006362 37737 ## 4 Brazil 2000 174594898 80488 ## 5 China 1999 1272915272 212258 ## 6 China 2000 1280428583 213766 # note without an assignment operator (&lt;-) this is not saved For more information and examples about pivoting refer to the Stanford Data Wrangling chapter on basic pivoting and the R for Data Science Chapter on tidy data.30 31 2.4.2 Creating New Variables When working with data you will want to create new variables. These can be numeric variables that combine values already present in the data or categorical variables that differentiate the values in some way. The mutate() function is used to create a new variable using the following syntax: mutate(data, new_var = formula). This first example, in the code chunk below, demonstrates how to make a new numeric variable using a formula consisting of two existing numeric variables. This creates a new column, cases_per_cap, that is the number of cases divided by the total population that year. The second new variable, ln_pop, demonstrates how to apply a function to an existing numeric variable to create a new variable. In this case the function is the natural log. mutate(table1, cases_per_cap = cases / population, ln_pop = log(population)) ## # A tibble: 6 × 6 ## country year cases population cases_per_cap ln_pop ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanistan 1999 745 19987071 0.0000373 16.8 ## 2 Afghanistan 2000 2666 20595360 0.000129 16.8 ## 3 Brazil 1999 37737 172006362 0.000219 19.0 ## 4 Brazil 2000 80488 174504898 0.000461 19.0 ## 5 China 1999 212258 1272915272 0.000167 21.0 ## 6 China 2000 213766 1280428583 0.000167 21.0 # on the left side of the equal sign is the name of the new variables # on the right side is the new variable You can use vectors outside of the data frame to create new variables, but must be careful when doing so. The vector must be the same length as the data frame. It is important to note that the first element will belong to the observation in the first row. You must make sure that you are assigning values to the correct observation, otherwise your data will become corrupted. The code chunk below shows an example of using a vector to create a new variable in table 1. new_var &lt;- c(0.5, 2.1, 3.4, 0.3, 0.78, 1.64) # these values do not correspond to anything mutate(table1, value = new_var) # the new var has a length of 6 so this works ## # A tibble: 6 × 5 ## country year cases population value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanistan 1999 745 19987071 0.5 ## 2 Afghanistan 2000 2666 20595360 2.1 ## 3 Brazil 1999 37737 172006362 3.4 ## 4 Brazil 2000 80488 174504898 0.3 ## 5 China 1999 212258 1272915272 0.78 ## 6 China 2000 213766 1280428583 1.64 # any other length would cause an error This next example demonstrates how to use the case_when() function. case_when() is very useful when creating a new categorical variable based on already existing numeric variables. This function does not have any explicit parameters. Instead, there can be any number of logical statements (e.g. cases / population &lt; 0.0001) with a corresponding ~. ~ creates a formula in R. On the other side of the ~ is the value of the variable if the logical statement evaluates to TRUE. Make sure only one formula evaluates as TRUE for each observation. The code chunk below demonstrates the syntax for case_when(). (new_table &lt;- mutate(table1, cases_per_cap = case_when(cases / population &lt; 0.0001 ~ &quot;low&quot;, cases / population &gt;= 0.0001 &amp; cases / population &lt; 0.0003 ~ &quot;medium&quot;, cases / population &gt;= 0.0003 ~ &quot;high&quot;))) ## # A tibble: 6 × 5 ## country year cases population cases_per_cap ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Afghanistan 1999 745 19987071 low ## 2 Afghanistan 2000 2666 20595360 medium ## 3 Brazil 1999 37737 172006362 medium ## 4 Brazil 2000 80488 174504898 high ## 5 China 1999 212258 1272915272 medium ## 6 China 2000 213766 1280428583 medium This example creates a new variable that designates the level of cases per capita as low, medium, or high. The new variable is a string instead of numeric. This variable is perfect for using the factor data type, as it has inherent ordered levels. The code chunk below demonstrates how to turn this variable into a factor. When using mutate, if you set something equal to a variable name already in use, it will overwrite that variable. mutate(new_table, cases_per_cap = factor(cases_per_cap, levels = c(&quot;low&quot;, &quot;medium&quot;, &quot;high&quot;))) ## # A tibble: 6 × 5 ## country year cases population cases_per_cap ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 Afghanistan 1999 745 19987071 low ## 2 Afghanistan 2000 2666 20595360 medium ## 3 Brazil 1999 37737 172006362 medium ## 4 Brazil 2000 80488 174504898 high ## 5 China 1999 212258 1272915272 medium ## 6 China 2000 213766 1280428583 medium 2.4.3 Selecting Columns In some cases, an imported data frame will have more variables than you need for your analysis. The select(data, cols) function allows you to choose columns to keep in a new data frame. The data parameter is the data frame to select columns from, and cols is the name of the columns to select. The code chunk below demonstrates how to use the select function using table1 as an example. select() is very useful when cleaning data as it allows you to easily discard data you do not need. You should always keep an original copy of the data as you received it in case you need to re-do your work. Save a modified data frame with a different name containing only the variables you need for analysis. select(table1, country, year) # this returns only the country and year columns ## # A tibble: 6 × 2 ## country year ## &lt;chr&gt; &lt;dbl&gt; ## 1 Afghanistan 1999 ## 2 Afghanistan 2000 ## 3 Brazil 1999 ## 4 Brazil 2000 ## 5 China 1999 ## 6 China 2000 # the everything function allows you to move the selected columns to the front # of the data frame, keeping all columns select(table1, year, population, everything()) ## # A tibble: 6 × 4 ## year population country cases ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1999 19987071 Afghanistan 745 ## 2 2000 20595360 Afghanistan 2666 ## 3 1999 172006362 Brazil 37737 ## 4 2000 174504898 Brazil 80488 ## 5 1999 1272915272 China 212258 ## 6 2000 1280428583 China 213766 2.4.4 Renaming Variables and Piping It is very important to make sure the names of the columns comply with the naming conventions of coding discussed in Section 2.1 and clearly indicate the variable to someone else. Most data sets have a code book that lists each variable and what it represents, but these names sometimes do not effectively identify the variable without having to refer to the code book. To rename the columns in a data frame use the rename() function available with the tidyverse. The code chunk below demonstrates this using table1. rename(table1, nation = country) ## # A tibble: 6 × 4 ## nation year cases population ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583 # the name you want to change the column to is on the left of the equal sign # the current name of the column is on the right of the equal sign Piping is an operator within R that allows the chaining of functions. It is a powerful tool that can be used with almost any function in the tidyverse. The output from the code before the pipe is inputted into the function immediately after it. I use the rename function as an example of how to use it. In the code chunk below, I use the rename function to change the names of two columns. #this can be done with multiple columns table1 |&gt; # the extra line is unnecessary but improves the readability of your code rename(nation = country, pos_test = cases) ## # A tibble: 6 × 4 ## nation year pos_test population ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583 The piping operator allows me to use the output of table1 as the data parameter for the next function, in this case the rename() function. The code chunk below demonstrates this by both pivoting and renaming longer_table using the piping operator. From this point forward, I will be using piping when demonstrating new concepts. longer_table |&gt; pivot_wider( names_from = type, values_from = value) |&gt; rename(pop = population, time = year) ## # A tibble: 6 × 4 ## country time pop cases ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanistan 1999 19987071 745 ## 2 Afghanistan 2000 20595360 2666 ## 3 Brazil 1999 172006362 37737 ## 4 Brazil 2000 174594898 80488 ## 5 China 1999 1272915272 212258 ## 6 China 2000 1280428583 213766 2.4.5 Filtering Data Filtering allows you to look at the subset of a data frame. It keeps rows that match a conditional statement (covered in Chapter 1). The syntax is as follows: filter(data, condition). The code chunk below filters Table 1, restricting it to only data pertaining to Afghanistan. This demonstrates how it can be very useful when dealing with categorical variables. table1 |&gt; filter(country == &quot;Afghanistan&quot;) # need to use a double equals sign for conditional expressions ## # A tibble: 2 × 4 ## country year cases population ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 # the match on the right side of the equals sign must be the same data type as the column referenced It is also very useful when dealing with numeric variables as well. The code chunk below demonstrates simple and more complex numeric filters. Simple conditional statements can be combined using &amp; (and) and | (or) operators. table1 |&gt; filter(population &gt; 20000000) ## # A tibble: 5 × 4 ## country year cases population ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanistan 2000 2666 20595360 ## 2 Brazil 1999 37737 172006362 ## 3 Brazil 2000 80488 174504898 ## 4 China 1999 212258 1272915272 ## 5 China 2000 213766 1280428583 # only keeps rows where population is greater than twenty million table1 |&gt; filter(population &lt; 20000000 | population &gt; 1000000000) ## # A tibble: 3 × 4 ## country year cases population ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 China 1999 212258 1272915272 ## 3 China 2000 213766 1280428583 # when using the | operator, if one or both of the conditionals evaluates to true, # then the whole statement evaluates as true and the row is kept table1 |&gt; filter(country == &quot;Afghanistan&quot; &amp; year == 2000) ## # A tibble: 1 × 4 ## country year cases population ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanistan 2000 2666 20595360 # when using the &amp; operator, both conditionals must be true for the whole # statement to evaluate as true and the row is kept The filter() function is wonderful for selecting subsets of data, but it does not allow you to reorder the rows according to a variable. For this we use the arrange() function. The basic syntax for arrange() is shown in the code chunk below. The first example shows the default ascending order the arrange() function uses. The second example shows how to instead use descending order by wrapping the column in the desc() function. The third example demonstrates what happens when multiple variables are included in the arrange() function. The function arranges according to the first variable and then without violating the arrangement of the first variable arranges according to the second, and so on. The final two examples show how arrange deals with characters. The most important difference between filter() and arrange() is that filter() loses observations when arrange() keeps all observations but just reorders them. table1 |&gt; arrange(year) # by default it arranges year in ascending order ## # A tibble: 6 × 4 ## country year cases population ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Brazil 1999 37737 172006362 ## 3 China 1999 212258 1272915272 ## 4 Afghanistan 2000 2666 20595360 ## 5 Brazil 2000 80488 174504898 ## 6 China 2000 213766 1280428583 table1 |&gt; arrange(desc(year)) # arranges year in descending order ## # A tibble: 6 × 4 ## country year cases population ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanistan 2000 2666 20595360 ## 2 Brazil 2000 80488 174504898 ## 3 China 2000 213766 1280428583 ## 4 Afghanistan 1999 745 19987071 ## 5 Brazil 1999 37737 172006362 ## 6 China 1999 212258 1272915272 table1 |&gt; arrange(year, desc(population)) ## # A tibble: 6 × 4 ## country year cases population ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 China 1999 212258 1272915272 ## 2 Brazil 1999 37737 172006362 ## 3 Afghanistan 1999 745 19987071 ## 4 China 2000 213766 1280428583 ## 5 Brazil 2000 80488 174504898 ## 6 Afghanistan 2000 2666 20595360 # first arranges by year (ascending) and then by population (descending) table1 |&gt; arrange(country) # arranges in alphabetical order ## # A tibble: 6 × 4 ## country year cases population ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583 table1 |&gt; arrange(desc(country)) # arranges in reverse alphabetical order ## # A tibble: 6 × 4 ## country year cases population ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 China 1999 212258 1272915272 ## 2 China 2000 213766 1280428583 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 Afghanistan 1999 745 19987071 ## 6 Afghanistan 2000 2666 20595360 2.4.6 Summarizing Data The summarize() function allows the creation of summary tables of the data. These tables are a crucial element of analysis. The function can be called either through summarize() or summarise(). Both do the exact same thing. The code chunk below shows an example displaying the mean of population, the mean the number of cases, and a count of the number of observations that go into each statistic. table1 |&gt; summarize(pop_mean = mean(population), mean(cases), count = n()) ## # A tibble: 1 × 3 ## pop_mean `mean(cases)` count ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 490072924. 91277. 6 # count shows the number of rows using the n() function A common problem is determining the unique values of a categorical variable. The code chunk below demonstrates how to do this using the reframe() and unique() functions. This method only works with categorical variables. An alternative way to do this is shown in the next section using the group_by() and summarize() functions. table1 |&gt; reframe(unique(country)) ## # A tibble: 3 × 1 ## `unique(country)` ## &lt;chr&gt; ## 1 Afghanistan ## 2 Brazil ## 3 China 2.4.7 Grouping Data When dealing with data that has categorical variables, it makes sense to analyze the data in context of each group within the categorical variable. This can be done through the group_by() function. group_by() on its own does not have any affect. It must be combined with another function and only works on categorical variables. The code chunk below demonstrates how it can be applied to countries in table1. When used in conjunction, it groups all observations with the same country and gives stats for each country instead of the data in totality as shown above. This function has the additional benefit of showing all possible values for the country categorical variable when used in conjunction with summarize(). table1 |&gt; group_by(country) |&gt; summarize(mean(cases)) ## # A tibble: 3 × 2 ## country `mean(cases)` ## &lt;chr&gt; &lt;dbl&gt; ## 1 Afghanistan 1706. ## 2 Brazil 59112. ## 3 China 213012 2.4.8 Merging Data Often, for analysis it will make sense to combine data from different sources to allow for a greater scope of analysis. This process is called merging data. To merge a data set with another one they must be relational. This is done through matching keys: variables that uniquely identify observations.32 There are two types of keys:33 primary key: uniquely identifies an observation in the original own data frame foreign key: uniquely identifies an observation in the data frame to merge Keys are not mutually exclusive; a variable can be a primary and foreign key. If a data frame lacks a primary key, you may need to make one. This can be done using mutate() and row_number(): mutate(data, unique_key = row_number()).34 This makes the row number into a variable uniquely identifying each observation. This is called a surrogate key.35 There are two common types of merges:36 mutating joins: matches observations according to their keys and then adds new variables from the new data frame to the original one filtering joins: filter observations from a data frame based on if they have a match in the second data frame There are other more advanced ways of merging data with complex filters that are not covered here. For information on those methods and a more complete explanation of this essential data science topic, refer to the R for Data Science chapter on relational data.37 There are two types of mutating joins:38 inner join - inner_join(x, y, by = \"key\") matches pairs of observations whenever their keys are equal unmatched observations are not included in the result outer join keeps all observations that appear in either one or both data sets left_join(x, y, by = \"key\") keeps all of the observations in the original data (x) right_join(x, y, by = \"key\") keeps all of the observations in the new data (y) full_join(x, y, by = \"key\") keeps all observation in both tables Below, I use four fictional data sets to demonstrate the mutating join functions discussed above. original &lt;- tibble(key = c(1,2,3,4,5), data = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;), nums = c(100, 110, 120, 130, 140)) new &lt;- tibble(new_key = c(2,3,4,6,7), new_data = c(10,30,24,53,67)) duplicate &lt;- tibble(key = c(1,2,2,2,3,4,5), data = c(&quot;May&quot;, &quot;Jul&quot;, &quot;Nov&quot;, &quot;Aug&quot;, &quot;Jun&quot;, &quot;Feb&quot;, &quot;Dec&quot;)) multiple &lt;- tibble(key = c(1,2,3,4,5), data = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;), values = c(&quot;Mon&quot;, &quot;Tues&quot;, &quot;Wed&quot;, &quot;Thurs&quot;, &quot;Fri&quot;)) The first thing you may notice is that in original and new, the column that contains the key does not have the same name or values. To join these you can either first rename the key columns so they have the same name or use the syntax of the first example below. The subsequent examples demonstrate how to use the other types of join function. # the piping operator fills in the x data parameter original |&gt; inner_join(new, by = c(&quot;key&quot; = &quot;new_key&quot;)) # syntax without renaming ## # A tibble: 3 × 4 ## key data nums new_data ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2 b 110 10 ## 2 3 c 120 30 ## 3 4 d 130 24 # keeps only matching observations new &lt;- new |&gt; rename(key = new_key) original |&gt; left_join(new, by = &quot;key&quot;) ## # A tibble: 5 × 4 ## key data nums new_data ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 a 100 NA ## 2 2 b 110 10 ## 3 3 c 120 30 ## 4 4 d 130 24 ## 5 5 e 140 NA # keeps all observations in original (x) data frame original |&gt; right_join(new, by = &quot;key&quot;) ## # A tibble: 5 × 4 ## key data nums new_data ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2 b 110 10 ## 2 3 c 120 30 ## 3 4 d 130 24 ## 4 6 &lt;NA&gt; NA 53 ## 5 7 &lt;NA&gt; NA 67 # keeps all observations in new (y) data frame original |&gt; full_join(new, by = &quot;key&quot;) # keeps all observations in both ## # A tibble: 7 × 4 ## key data nums new_data ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 a 100 NA ## 2 2 b 110 10 ## 3 3 c 120 30 ## 4 4 d 130 24 ## 5 5 e 140 NA ## 6 6 &lt;NA&gt; NA 53 ## 7 7 &lt;NA&gt; NA 67 # when there is not a corresponding observation in the match and the observation is kept, NA is used to fill it in as missing If the by = parameter is not specified, by = NULL. This means that the key will be all variables that the two data frames share in common. This is called a natural join. Most of the time it is good practice to specify the key or keys you want to use to prevent errors. You must always check the data after joining to make sure it is correct. The duplicate data frame and the code chunk below demonstrate what happens when there are multiple observations that correspond to the same key. Usually, only one of the data frames will contain observations with duplicate matching observations. If this is not the case, then it there most likely is an error in one of the data frames. original |&gt; inner_join(duplicate, by = &quot;key&quot;) ## # A tibble: 7 × 4 ## key data.x nums data.y ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 a 100 May ## 2 2 b 110 Jul ## 3 2 b 110 Nov ## 4 2 b 110 Aug ## 5 3 c 120 Jun ## 6 4 d 130 Feb ## 7 5 e 140 Dec When a variable is mutated in from the new (y) data frame that has the same name as one in the original (x) data frame, the variables are denoted data.x and data.y. This is demonstrated in the code chunk above. Sometimes, one variable will not be able to uniquely identify observations as discussed previously. The multiple data frame and the example in the code chunk below demonstrate the syntax of using multiple variables to identify observations. original |&gt; inner_join(multiple, by = c(&quot;key&quot;, &quot;data&quot;)) ## # A tibble: 5 × 4 ## key data nums values ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 a 100 Mon ## 2 2 b 110 Tues ## 3 3 c 120 Wed ## 4 4 d 130 Thurs ## 5 5 e 140 Fri 2.4.9 Working Example This section’s example is from Appendix B.22 of Introduction to Time Series Analysis and Forecasting.39 In the code chunk below, I read in the data from an excel file and printed it. It is a univariate time series of Denmark’s crude oil production (in thousands of tons).40 I will use methods discussed across this section to clean this data set. (oil_production &lt;- read_excel(&quot;oil_prod.xlsx&quot;, skip = 2)) ## # A tibble: 14 × 13 ## Year Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2001 1372 1439 1499 1399 1340 1018 1121 1411 1560 1492 1578 1709 ## 2 2002 1627 1457 1536 1560 1575 1431 1567 1267 1421 1619 1531 1592 ## 3 2003 1617 1445 1598 1464 1482 1514 1406 1520 1560 1578 1574 1550 ## 4 2004 1560 1335 1626 1645 1685 1617 1715 1471 1607 1726 1543 1731 ## 5 2005 1577 1536 1632 1605 1568 1541 1518 1591 1459 1536 1485 1470 ## 6 2006 1459 1351 1471 1330 1518 1377 1547 1364 1086 1456 1429 1450 ## 7 2007 1266 1194 1290 1256 1290 1258 1240 1340 1159 1382 1264 1231 ## 8 2008 1255 1024 1242 1101 1275 1138 1268 1141 1085 1196 1155 1156 ## 9 2009 1201 1067 1140 1110 1081 1066 1112 1061 1129 1051 925 959 ## 10 2010 1095 937 1014 1116 1061 906 1110 710 1014 1080 1009 1106 ## 11 2011 987 791 964 925 1090 872 937 906 861 859 930 818 ## 12 2012 826 830 854 867 866 860 853 820 724 824 819 838 ## 13 2013 787 752 808 764 756 682 741 679 635 720 687 671 ## 14 2014 675 637 691 659 -- -- -- -- -- -- -- -- The main issue with the data is that the columns indicate the month and each row contains many observations and represents a year. The indication of time must always be contained to one column and each row must only contain a single observation. Additionally, the textbook uses -- instead of NA to indicate missing observations and the columns are different data types despite containing observations of the same numeric variable. When this data is cleaned it will be a data frame with two columns, one containing the time and the other containing the oil production. The first step is to change the data type of the columns that are not doubles (May to Dec). I use the mutate_if(data, .predicate, .funs) function for this. mutate_if() allows me to change all columns that are characters (.predicate) to doubles (.funs). Look up the documentation for the function for more information on conditional mutates and further examples. This process introduces missing values to the data, seen through the warning produced. (clean_oil_production &lt;- mutate_if(oil_production, is.character, as.double)) ## Warning: There were 8 warnings in `mutate()`. ## The first warning was: ## ℹ In argument: `May = .Primitive(&quot;as.double&quot;)(May)`. ## Caused by warning: ## ! NAs introduced by coercion ## ℹ Run `dplyr::last_dplyr_warnings()` to see the 7 remaining warnings. ## # A tibble: 14 × 13 ## Year Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2001 1372 1439 1499 1399 1340 1018 1121 1411 1560 1492 1578 1709 ## 2 2002 1627 1457 1536 1560 1575 1431 1567 1267 1421 1619 1531 1592 ## 3 2003 1617 1445 1598 1464 1482 1514 1406 1520 1560 1578 1574 1550 ## 4 2004 1560 1335 1626 1645 1685 1617 1715 1471 1607 1726 1543 1731 ## 5 2005 1577 1536 1632 1605 1568 1541 1518 1591 1459 1536 1485 1470 ## 6 2006 1459 1351 1471 1330 1518 1377 1547 1364 1086 1456 1429 1450 ## 7 2007 1266 1194 1290 1256 1290 1258 1240 1340 1159 1382 1264 1231 ## 8 2008 1255 1024 1242 1101 1275 1138 1268 1141 1085 1196 1155 1156 ## 9 2009 1201 1067 1140 1110 1081 1066 1112 1061 1129 1051 925 959 ## 10 2010 1095 937 1014 1116 1061 906 1110 710 1014 1080 1009 1106 ## 11 2011 987 791 964 925 1090 872 937 906 861 859 930 818 ## 12 2012 826 830 854 867 866 860 853 820 724 824 819 838 ## 13 2013 787 752 808 764 756 682 741 679 635 720 687 671 ## 14 2014 675 637 691 659 NA NA NA NA NA NA NA NA Next, the data must be pivoted. In the code chunk below, I use pivot_longer() function to create a single column for all the oil production values and a new column indicating the month. (clean_oil_production &lt;- pivot_longer(clean_oil_production, -(Year), names_to = &quot;month&quot;, values_to = &quot;oil_prod&quot;)) # -(Year) selects all columns except year ## # A tibble: 168 × 3 ## Year month oil_prod ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2001 Jan 1372 ## 2 2001 Feb 1439 ## 3 2001 Mar 1499 ## 4 2001 Apr 1399 ## 5 2001 May 1340 ## 6 2001 Jun 1018 ## 7 2001 Jul 1121 ## 8 2001 Aug 1411 ## 9 2001 Sep 1560 ## 10 2001 Oct 1492 ## # ℹ 158 more rows Next, I need to join the month and year into a single string variable that can be read by parse_date_time(). In the code chunk below, I use the str_c() function (from stringr) within mutate() to join the two separate Year and month variables. stringr is a package included in the tidyverse for manipulating strings. Below, I have included the cheat sheets for manipulating strings with stringr for reference.41 For more information about working with strings, refer to the strings chapter of R for Data Science.42 (clean_oil_production &lt;- clean_oil_production |&gt; mutate(time = str_c(Year, month, sep = &quot; &quot;))) ## # A tibble: 168 × 4 ## Year month oil_prod time ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 2001 Jan 1372 2001 Jan ## 2 2001 Feb 1439 2001 Feb ## 3 2001 Mar 1499 2001 Mar ## 4 2001 Apr 1399 2001 Apr ## 5 2001 May 1340 2001 May ## 6 2001 Jun 1018 2001 Jun ## 7 2001 Jul 1121 2001 Jul ## 8 2001 Aug 1411 2001 Aug ## 9 2001 Sep 1560 2001 Sep ## 10 2001 Oct 1492 2001 Oct ## # ℹ 158 more rows Now that I have a unified time variable in the form a string, I need to replace it with a date time object using parse_date_time(). (clean_oil_production &lt;- clean_oil_production |&gt; mutate(time = parse_date_time(time, orders = &quot;ym&quot;))) ## # A tibble: 168 × 4 ## Year month oil_prod time ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dttm&gt; ## 1 2001 Jan 1372 2001-01-01 00:00:00 ## 2 2001 Feb 1439 2001-02-01 00:00:00 ## 3 2001 Mar 1499 2001-03-01 00:00:00 ## 4 2001 Apr 1399 2001-04-01 00:00:00 ## 5 2001 May 1340 2001-05-01 00:00:00 ## 6 2001 Jun 1018 2001-06-01 00:00:00 ## 7 2001 Jul 1121 2001-07-01 00:00:00 ## 8 2001 Aug 1411 2001-08-01 00:00:00 ## 9 2001 Sep 1560 2001-09-01 00:00:00 ## 10 2001 Oct 1492 2001-10-01 00:00:00 ## # ℹ 158 more rows Finally, I need to drop all missing values using the drop_na() function and select only the corrected time variable and the newly created oil_prod variable to create the final clean data set. (clean_oil_production &lt;- clean_oil_production |&gt; drop_na() |&gt; select(time, oil_prod)) ## # A tibble: 160 × 2 ## time oil_prod ## &lt;dttm&gt; &lt;dbl&gt; ## 1 2001-01-01 00:00:00 1372 ## 2 2001-02-01 00:00:00 1439 ## 3 2001-03-01 00:00:00 1499 ## 4 2001-04-01 00:00:00 1399 ## 5 2001-05-01 00:00:00 1340 ## 6 2001-06-01 00:00:00 1018 ## 7 2001-07-01 00:00:00 1121 ## 8 2001-08-01 00:00:00 1411 ## 9 2001-09-01 00:00:00 1560 ## 10 2001-10-01 00:00:00 1492 ## # ℹ 150 more rows I separated these steps into different stages for clarity. These steps can be completed continuously using piping as demonstrated below: read_excel(&quot;oil_prod.xlsx&quot;, skip = 2) |&gt; mutate_if(is.character, as.double) |&gt; pivot_longer(-(Year), names_to = &quot;month&quot;, values_to = &quot;oil_prod&quot;) |&gt; mutate(time = parse_date_time(str_c(Year, month, sep = &quot; &quot;), orders = &quot;ym&quot;)) |&gt; drop_na() |&gt; select(time, oil_prod) ## Warning: There were 8 warnings in `mutate()`. ## The first warning was: ## ℹ In argument: `May = .Primitive(&quot;as.double&quot;)(May)`. ## Caused by warning: ## ! NAs introduced by coercion ## ℹ Run `dplyr::last_dplyr_warnings()` to see the 7 remaining warnings. ## # A tibble: 160 × 2 ## time oil_prod ## &lt;dttm&gt; &lt;dbl&gt; ## 1 2001-01-01 00:00:00 1372 ## 2 2001-02-01 00:00:00 1439 ## 3 2001-03-01 00:00:00 1499 ## 4 2001-04-01 00:00:00 1399 ## 5 2001-05-01 00:00:00 1340 ## 6 2001-06-01 00:00:00 1018 ## 7 2001-07-01 00:00:00 1121 ## 8 2001-08-01 00:00:00 1411 ## 9 2001-09-01 00:00:00 1560 ## 10 2001-10-01 00:00:00 1492 ## # ℹ 150 more rows 2.5 Data Sources This section outlines refutable data sources that have a robust collection of variables. This makes them ideal for exploring your own interests in data analysis or for creating a project of your own. This is not a comprehensive list, but will allow you to access most data available on the internet and access a variety of refutable and significant economic variables. 2.5.1 Tidycensus Tidycensus is an R package that allows users to easily access US census data. A complete explanation of Census data and how to use tidycensus is given in Kyle Walker’s Analyzing US Census Data: Methods, Maps, and Models in R.43 Walker provides a comprehensive and updated review of how to use Census data with R. tidycensus is an example of a package that interacts with an API (Application Programming Interface). APIs are amazing tools for getting access to underlying data on the internet from a wide variety of sources. For more information on APIs refer this chapter from Stanford’s Data Wrangling.44 library(tidycensus) Tidycensus is an example of a R package that is a wrapper for an API, making the process of obtaining data easier.45 The census has a variety of APIs available, but the ones most applicable to your work are: Decennial Census Consists of the data from the survey sent to each U.S. household every 10 years, beginning in 179046 Until the 2000, the decennial census consisted of a short form, which every household filled out, and a long form, a long form version with additional questions received by 1 in 6 Americans47 Most accurate population data, but only available every 10 years useful if a census year lines up with the time frame of your data occurs in years ending in 0 (e.g 1990, 2000) the American Community Survey (ACS) After 2000, the long form census became the ACS and was administered every year to a sample of 3.5 million households48 Consists of samples every year or every five years One year estimates are more current but have a larger margin of error, making five year estimates more useful49 includes a wide variety of variables on social, economic, housing, and demographic aspects very good data on racial breakdown the Population Estimates Program (PEP) Population estimates for non-decennial census years using decennial census data as well as birth, death, and migration rates50 Also allows access to indicator variables used in estimation Uses more accurate techniques for population estimation than ACS population estimates51 Before using Tidycensus you need to get a Census Bureau API key and activate it. This can be done by completing these steps:52 Request a key here You will receive an email with they key Run census_api_key(\"YOUR KEY GOES HERE\", install = TRUE) replace YOUR_KEY_GOES_HERE with your Census key from step 1 Restart R (Ctrl/Cmd + Shift +F10) These steps only need to be completed once. The first step to retrieving data is to select the variables you want using the load_variables(year, dataset = ) function. The options for the year and dataset parameters are outlined below:53 Decennial Census dataset = \"sf1\": short form census available for 2000 and 2010 \"sf2\": range of population and housing unit characteristics available for 2000 and 2010 \"sf3\" and \"sf4\": long form census data on detailed demographic information such as income and occupation available for 1790 to 2000, every 10 years note portions of the 2020 census data are available this is only available through load_variables(year = 2020, dataset = \"pl\") ACS dataset = \"acs5\": 5 year ACS year refers to the end-year of the sample period e.g. year = 2019 refers to the 2015 through 2019 sample ACS end-years 2009 to 2019 supported \"acs1\": 1 year ACS ACS end-years 2005 to 2021 supported PEP the PEP estimates are not available through the load_variables() function instead you use the get_estimates() function the entire data set is far too large to download, so you must use parameters to download smaller subsets the use of this function is covered in the section below covering retrieving variables The load_variables() function returns a tibble with three variables: name: the variable code label: a description of the variable concpet: a broader categorization (vars &lt;- load_variables(year = 2021, dataset = &quot;acs1&quot;)) ## # A tibble: 36,400 × 3 ## name label concept ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 B01001A_001 Estimate!!Total: SEX BY AGE (WHITE ALONE) ## 2 B01001A_002 Estimate!!Total:!!Male: SEX BY AGE (WHITE ALONE) ## 3 B01001A_003 Estimate!!Total:!!Male:!!Under 5 years SEX BY AGE (WHITE ALONE) ## 4 B01001A_004 Estimate!!Total:!!Male:!!5 to 9 years SEX BY AGE (WHITE ALONE) ## 5 B01001A_005 Estimate!!Total:!!Male:!!10 to 14 years SEX BY AGE (WHITE ALONE) ## 6 B01001A_006 Estimate!!Total:!!Male:!!15 to 17 years SEX BY AGE (WHITE ALONE) ## 7 B01001A_007 Estimate!!Total:!!Male:!!18 and 19 years SEX BY AGE (WHITE ALONE) ## 8 B01001A_008 Estimate!!Total:!!Male:!!20 to 24 years SEX BY AGE (WHITE ALONE) ## 9 B01001A_009 Estimate!!Total:!!Male:!!25 to 29 years SEX BY AGE (WHITE ALONE) ## 10 B01001A_010 Estimate!!Total:!!Male:!!30 to 34 years SEX BY AGE (WHITE ALONE) ## # ℹ 36,390 more rows This tibble allows you to select the desired variables from the selected data set. These variables are coded so it is important to make a list of the desired variables codes for retrieving the actual data. The sheer number of variables is overwhelming, so it is important to be able to narrow down to what you want through filtering. I have found the most success by first filtering by concept and then looking at the individual label. It is easiest to view the data frame from the R environment and filter through the button in the top left of the window. The picture below shows the results of filtering for aggregate family income from the 1-year ACS data set from 2021. After selecting the desired variables, copy down the variable codes shown in the name column. The best way to do this is to save them into a vector, as demonstrated below. This allows you to just reference that vector in the variables argument of the retrieval function. The function used to get the data depends on the type of data you want:54 decennial census use get_decennial(geography, variables = , year = ) geography = refers to the geographical unit of each observation lowest level is \"tract\", largest level is \"us\" a full list of the options is available here55 variables = refers to the variables to get set this equal to the vector containing the names of desired variables year = refers to the sample end-year ACS use get_acs(geography, variables = , year = , survey =) identical parameters are the same as above survey = refers to the acs survey you want the default is \"acs5\" other option is \"acs1\" PEP use get_estimates(geography = , product = , year = , breakdown = , breakdown_labels = ) identical parameters are the same as above product = refers to the set of variables to get the options are \"population\", \"components\", \"housing\", \"characteristics\" breakdown = allows you to break down the variables by different categories the options are \"AGEGROUP\", \"RACE\", \"SEX\", or \"HISP\" when using breakdown = it is best to set breakdown_labels = TRUE so the breakdown differences are included In the code chunk below I demonstrate how to create a variable vector and retrieve the variables with the get_acs() function. variables &lt;- c(&quot;B01001_026&quot;, &quot;B01001_002&quot;) # can put any number of variables in this vector (acs_data &lt;- get_acs(geography = &quot;state&quot;, variables = variables, year = 2021, survey = &quot;acs1&quot;)) ## Getting data from the 2021 1-year ACS ## The 1-year ACS provides data for geographies with populations of 65,000 and greater. ## # A tibble: 104 × 5 ## GEOID NAME variable estimate moe ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 01 Alabama B01001_002 2445896 5868 ## 2 01 Alabama B01001_026 2593981 5868 ## 3 02 Alaska B01001_002 383121 2429 ## 4 02 Alaska B01001_026 349552 2429 ## 5 04 Arizona B01001_002 3629620 2852 ## 6 04 Arizona B01001_026 3646696 2852 ## 7 05 Arkansas B01001_002 1493681 4590 ## 8 05 Arkansas B01001_026 1532210 4590 ## 9 06 California B01001_002 19618934 6432 ## 10 06 California B01001_026 19618902 6432 ## # ℹ 94 more rows One thing to note about the census data is that it often comes in a form where it needs to be pivoted. Below, I demonstrate how to pivot this data into a clean form better suited for analysis and visualization: acs_data |&gt; pivot_wider(names_from = c(variable), values_from = c(estimate, moe)) |&gt; rename(male_pop = estimate_B01001_002, female_pop = estimate_B01001_026, male_pop_moe = moe_B01001_002, female_pop_moe = moe_B01001_026) ## # A tibble: 52 × 6 ## GEOID NAME male_pop female_pop male_pop_moe female_pop_moe ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 01 Alabama 2445896 2593981 5868 5868 ## 2 02 Alaska 383121 349552 2429 2429 ## 3 04 Arizona 3629620 3646696 2852 2852 ## 4 05 Arkansas 1493681 1532210 4590 4590 ## 5 06 California 19618934 19618902 6432 6432 ## 6 08 Colorado 2943037 2869032 3980 3980 ## 7 09 Connecticut 1768045 1837552 2237 2237 ## 8 10 Delaware 485908 517476 1201 1201 ## 9 11 District of Columbia 319025 351025 601 601 ## 10 12 Florida 10714520 11066608 8241 8241 ## # ℹ 42 more rows 2.5.2 IPUMS IPUMS is a collection of social and economic data readily available on the internet. Their data sets aggregate data across different US government agencies and international data sources, including census data, the National Science Foundation, the Bureau of Labor Statistics, the Center for Disease Control, and the Food and Drug Administration. They also offer international, health, and higher education focused data sets. This allows access to census data for years that are not available in the tidycensus package. To get data you select the variable and the sample (source and time) into a cart and download the data as a .csv file on their website. 2.5.3 Google Trends Google Trends is a website that allows you to access data on the number of times a term was searched on Google by region and time period. This data can be incredibly useful in regressions and can be indicative of what is on people’s mind at a given time. This link provides a guide on how to access this data either in the format of a CSV or directly within R through the gtrendsR package.56 2.5.4 Scraping Sometimes you are able to look at data on the internet, but it is not available for download. Scraping is the process by which you are able to access the data you can see through the html code of the website. Not all websites are able to be scraped easily, but many are. Scraping is a very useful skill in the world of data science. In R, scraping can be done through the rvest package. This is covered extensively here in the Stanford Data Wrangling book.57 This is a very useful tool and is considered to be an entire branch of data science. 2.6 Conclusion This chapter provides a comprehensive overview of data. By this point, using the skills above, you should be able to read almost any form of data into a data frame within R, manipulate and clean data, and get data from the variety of recommended data sources or through scraping. These skills will give you a concrete foundation for data wrangling. This book is meant to give a functional overview of these topics while referencing resources that provide more information. Do not hesitate to look into R for Data Science, Stanford’s Data Wrangling, and Analyzing US Census Data. These resources provide more in-depth explanations into these topics. References "],["data_viz.html", "3 Data Vizualization 3.1 The Grammar of Graphics 3.2 Aesthetics 3.3 Faceting 3.4 Geoms: Types of Plots 3.5 Modifying Data and Axes 3.6 Titles 3.7 Plotting Time Series 3.8 Saving and Showing Graphics 3.9 Conclusion", " 3 Data Vizualization In this chapter I will cover how to visualize data using ggplot2, a package included in the tidyverse. ggplot2 provides a few distinct advantages. It is integrated into the tidyverse, allowing it to interact with data frames (tibbles) in meaningful ways to produce better looking and more customizable graphs using less code. It also uses a layered format, allowing multiple visualizations of the same type to be combined and allowing for easy modification of different aspects of visualization. This will be discussed in greater detail in Section 4.1: The Grammar of Graphics. For work in this chapter we will be using a couple different packages. As always, we will use the tidyverse, which contains ggplot2, the focus of this chapter.5859 Additionally we will use nycflights13, a package that provides sample data to work with as we learn the tools available through ggplot2.60 library(tidyverse) library(nycflights13) nycflights13 contains a variety of data sets pertaining to flights departing New York City in 2013.61 The code chunk below shows the three most prominent ones. flights ## # A tibble: 336,776 × 19 ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 819 ## 2 2013 1 1 533 529 4 850 830 ## 3 2013 1 1 542 540 2 923 850 ## 4 2013 1 1 544 545 -1 1004 1022 ## 5 2013 1 1 554 600 -6 812 837 ## 6 2013 1 1 554 558 -4 740 728 ## 7 2013 1 1 555 600 -5 913 854 ## 8 2013 1 1 557 600 -3 709 723 ## 9 2013 1 1 557 600 -3 838 846 ## 10 2013 1 1 558 600 -2 753 745 ## # ℹ 336,766 more rows ## # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, ## # tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, ## # hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; weather ## # A tibble: 26,115 × 15 ## origin year month day hour temp dewp humid wind_dir wind_speed ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 EWR 2013 1 1 1 39.0 26.1 59.4 270 10.4 ## 2 EWR 2013 1 1 2 39.0 27.0 61.6 250 8.06 ## 3 EWR 2013 1 1 3 39.0 28.0 64.4 240 11.5 ## 4 EWR 2013 1 1 4 39.9 28.0 62.2 250 12.7 ## 5 EWR 2013 1 1 5 39.0 28.0 64.4 260 12.7 ## 6 EWR 2013 1 1 6 37.9 28.0 67.2 240 11.5 ## 7 EWR 2013 1 1 7 39.0 28.0 64.4 240 15.0 ## 8 EWR 2013 1 1 8 39.9 28.0 62.2 250 10.4 ## 9 EWR 2013 1 1 9 39.9 28.0 62.2 260 15.0 ## 10 EWR 2013 1 1 10 41 28.0 59.6 260 13.8 ## # ℹ 26,105 more rows ## # ℹ 5 more variables: wind_gust &lt;dbl&gt;, precip &lt;dbl&gt;, pressure &lt;dbl&gt;, ## # visib &lt;dbl&gt;, time_hour &lt;dttm&gt; planes ## # A tibble: 3,322 × 9 ## tailnum year type manufacturer model engines seats speed engine ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 N10156 2004 Fixed wing multi… EMBRAER EMB-… 2 55 NA Turbo… ## 2 N102UW 1998 Fixed wing multi… AIRBUS INDU… A320… 2 182 NA Turbo… ## 3 N103US 1999 Fixed wing multi… AIRBUS INDU… A320… 2 182 NA Turbo… ## 4 N104UW 1999 Fixed wing multi… AIRBUS INDU… A320… 2 182 NA Turbo… ## 5 N10575 2002 Fixed wing multi… EMBRAER EMB-… 2 55 NA Turbo… ## 6 N105UW 1999 Fixed wing multi… AIRBUS INDU… A320… 2 182 NA Turbo… ## 7 N107US 1999 Fixed wing multi… AIRBUS INDU… A320… 2 182 NA Turbo… ## 8 N108UW 1999 Fixed wing multi… AIRBUS INDU… A320… 2 182 NA Turbo… ## 9 N109UW 1999 Fixed wing multi… AIRBUS INDU… A320… 2 182 NA Turbo… ## 10 N110UW 1999 Fixed wing multi… AIRBUS INDU… A320… 2 182 NA Turbo… ## # ℹ 3,312 more rows ggplot2 includes sample data sets provided within the package as well. These data sets are displayed in the code chunk below. diamonds ## # A tibble: 53,940 × 10 ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 3.95 3.98 2.43 ## 2 0.21 Premium E SI1 59.8 61 326 3.89 3.84 2.31 ## 3 0.23 Good E VS1 56.9 65 327 4.05 4.07 2.31 ## 4 0.29 Premium I VS2 62.4 58 334 4.2 4.23 2.63 ## 5 0.31 Good J SI2 63.3 58 335 4.34 4.35 2.75 ## 6 0.24 Very Good J VVS2 62.8 57 336 3.94 3.96 2.48 ## 7 0.24 Very Good I VVS1 62.3 57 336 3.95 3.98 2.47 ## 8 0.26 Very Good H SI1 61.9 55 337 4.07 4.11 2.53 ## 9 0.22 Fair E VS2 65.1 61 337 3.87 3.78 2.49 ## 10 0.23 Very Good H VS1 59.4 61 338 4 4.05 2.39 ## # ℹ 53,930 more rows mpg ## # A tibble: 234 × 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 audi a4 1.8 1999 4 auto… f 18 29 p comp… ## 2 audi a4 1.8 1999 4 manu… f 21 29 p comp… ## 3 audi a4 2 2008 4 manu… f 20 31 p comp… ## 4 audi a4 2 2008 4 auto… f 21 30 p comp… ## 5 audi a4 2.8 1999 6 auto… f 16 26 p comp… ## 6 audi a4 2.8 1999 6 manu… f 18 26 p comp… ## 7 audi a4 3.1 2008 6 auto… f 18 27 p comp… ## 8 audi a4 quattro 1.8 1999 4 manu… 4 18 26 p comp… ## 9 audi a4 quattro 1.8 1999 4 auto… 4 16 25 p comp… ## 10 audi a4 quattro 2 2008 4 manu… 4 20 28 p comp… ## # ℹ 224 more rows economics ## # A tibble: 574 × 6 ## date pce pop psavert uempmed unemploy ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1967-07-01 507. 198712 12.6 4.5 2944 ## 2 1967-08-01 510. 198911 12.6 4.7 2945 ## 3 1967-09-01 516. 199113 11.9 4.6 2958 ## 4 1967-10-01 512. 199311 12.9 4.9 3143 ## 5 1967-11-01 517. 199498 12.8 4.7 3066 ## 6 1967-12-01 525. 199657 11.8 4.8 3018 ## 7 1968-01-01 531. 199808 11.7 5.1 2878 ## 8 1968-02-01 534. 199920 12.3 4.5 3001 ## 9 1968-03-01 544. 200056 11.7 4.1 2877 ## 10 1968-04-01 544 200208 12.3 4.6 2709 ## # ℹ 564 more rows This chapter is meant to serve as a guide on how to produce effective graphics using tidy data. Throughout the chapter, I will link more comprehensive resources that go into further depth about the grammar of graphics and the intricacies of ggplot2. This chapter provides an outline of the steps required to produce visualizations, as well as a cursory introduction to the foundational theory of effective graphics. 3.1 The Grammar of Graphics ggplot2 uses the theoretical framework called the grammar of graphics as the basis for its organization. There are three essential components to a graphic:62 data: the clean data containing the variable(s) of interest geom: the type of geometric object in the plot e.g. line, point, bar, box aes: aesthetic attributes of the geometric object e.g. x/y variables, color, shape, size can be mapped (coordinated) to variables For our first plot, we will plot the displ and hwy variables from the mpg data set. The code chunk below demonstrates the most basic syntax for producing a graphic using ggplot.63 (example1 &lt;- ggplot(data = mpg, aes(x = displ, y = hwy)) + # data =, x =, and y = are not required geom_point()) In this plot, displ refers to engine displacement (in liters) and hwy refers to highway miles per gallon. It is always crucial to know what each variable you are working with refers to. If you are unsure, check the code book for your data set. For the data sets we are working with in this chapter, their code books can be found in their documentation. This link provides the code book for mpg. In terms of the grammar discussed above, the data is mpg, the geom is a scatter plot (designated by adding the + geom_point()), and the aes refers to the variables assigned to each axis within aes() in the first line. I saved this plot as example1 and put parentheses around the whole statement so it would print. Below, I break example1 into its different components. In the first line, the data = parameter tells ggplot2 the relevant data frame. The x and y parameters within aes() tell ggplot which variables are assigned to each axis. This covers the most basic components of each visualization, taking care of the data and aes features of the visualization. There is no geom in the example below, so only a blank graph with assigned axes is outputted. ggplot(data = mpg, aes(x = displ, y = hwy)) After establishing the basic grid where the data will be visualized, the next step is to add geoms. Our first example graph used the geom geom_point() to create a scatter plot. One of the most powerful features of ggplot2 is its ability to layer multiple geoms over the same visualization. Only certain geoms are able to be layered together. The code chunk below demonstrates how to use multiple geoms. Each one can be added using the following code template: + geom_function(). Different types of geoms will be covered in detail later in Section 4.4: Geoms. ggplot(data = mpg, aes(x = displ, y = hwy)) + geom_point() + geom_smooth() # the geom_smooth function adds a line of best fit with a confidence interval ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; # look at the documentation of geom_smooth to determine the method it uses to smooth If you would like to vary the parameters in ggplot() between geoms, specify them differently within each geom function instead of within ggplot(). It is important to note that everything written within ggplot() applies to all geoms. The code chunk below demonstrates how to layer two geoms using different variables. To differentiate between the two different variables, you must assign each one a different color. To assign an attribute that is not mapped to an aesthetic (within aes()) place it after aes() as demonstrated below. The two different variables on the same axis (the y-axis in this example) must share a unit for this to make sense (both cty and hwy are in miles per gallon). ggplot(data = mpg) + geom_point(aes(x = displ, y = hwy), color = &quot;black&quot;) + geom_point(aes(x = displ, y = cty), color = &quot;red&quot;) The issue with the plot above is that it does not automatically generate a legend. While this demonstrates how geoms can be layered, there is a better way to make this graph covered in Section 4.2.1: Color. 3.2 Aesthetics The most basic aesthetic attributes included in just about every type of plot are the assignment of the axes. Some types of plots (e.g histogram) only require the x-axis. Other types of aesthetic attributes can be used to differentiate between observations based on categorical or numeric variables. The first important differentiation about aesthetics, alluded to earlier, is the difference between putting something within aes() and putting something behind it. When an attribute is within aes(), the computer assumes that you are referring to a variable within the data. When an attribute is after the aesthetics (e.g.aes(), color = \"blue\"), then it applies the aesthetic change to the whole geom without mapping it to a variable. The difference is demonstrated in the code chunk below using the example1 scatter plot and in the examples dealing with different types of aesthetics. # when color is within aes(), the computer thinks &quot;red&quot; is a categorical variable and incorrectly makes a legend ggplot(data = mpg) + geom_point(aes(x = displ, y = hwy, color = &quot;red&quot;)) # when the color is after aes(), all points are colored red ggplot(data = mpg) + geom_point(aes(x = displ, y = hwy), color = &quot;red&quot;) The important point here is that everything within aes() corresponds to a variable, when everything afterwards modifies an attribute of the visualization in a fixed manner. This section will cover the basic attributes of a scatter plot, through a variety of examples using the data sets mentioned at the beginning of the chapter. Each of these attributes has different visual aspects that make them better or worse for categorical or continuous variables. Replicating and modifying these examples is the best way to practice getting comfortable making visualizations. All examples in this section will modify the example1 plot, which uses the mpg data set. 3.2.1 Color Color is a powerful attribute that lends itself well to both categorical variables and continuous ones. When used outside of aesthetic mapping purposes, it can be used to create graphics that are more visually appealing. When trying to communicate information through color, make sure that the uninformed reader is able to easily differentiate between categories or read the scale if the variable is continuous. Experimentation using different attributes to represent a variable is how to find the clearest way to communicate meaning through aesthetics. In the plot below, color is used to differentiates between different classes of car, a categorical variable. Importantly, each class of car is identifiable through the legend. ggplot(data = mpg) + geom_point(aes(x = displ, y = hwy, color = class)) The next example uses scaled color to represent the continuous variable cty, referring to the city miles per gallon. Often, when there are many points in a scatter plot or a wide range of values represented by color, the visualization can become unclear to the observer. Each visualization is unique and must be individually assessed in this respect. ggplot(data = mpg) + geom_point(aes(x = displ, y = hwy, color = cty)) Using the color aesthetic addresses the problem of layering geoms to manually set different colors above. Unfortunately, the mpg data set does not come in a format where this can be done without wrangling the data. The code chunk below demonstrates how to modify the data using pivot_longer(), creating a single mpg variable where a new categorical variable designates if the mpg variable refers to highway or city. That new cateogrical variable is then mapped to color. mpg |&gt; pivot_longer(c(hwy, cty), names_to = &quot;mpg_type&quot;, values_to = &quot;mpg&quot;) |&gt; ggplot(aes(x=displ, y=mpg, color=mpg_type)) + geom_point() 3.2.2 Shape Shape is only used to represent categorical variables. It can be used to represent a continuous variable, but only if that variable is simplified into a categorical variable that designates a level or range for the continuous variable (e.g. low, medium, high). The code chunk below shows an example of mapping shape to the drive train variable (drv) and changing the shape for look without mapping to a variable. # mapping shape to the class variable ggplot(data = mpg) + geom_point(aes(x = displ, y = hwy, shape = drv)) # changing shape for look only ggplot(data = mpg) + geom_point(aes(x = displ, y = hwy), shape = 17) For information of which shape corresponds to which number, when not using mapping, look at the aesthetics mapping section of R for Data Science.64 3.2.3 Size Size can be used to designate categorical variables, but often it can be hard to differentiate between levels and it makes the graph less legible. I would recommend only using size with a continuous variable, as it lends itself well to meaningful visual comparisons on a continuous scale. The example below maps size to the city miles per gallon variable (cty) from mpg. ggplot(data = mpg) + geom_point(aes(x = displ, y = hwy, size = cty)) As demonstrated above using color, the size parameter can also be used outside of aes() to uniformly change all points. Often, when a graph is hard to read, reducing the size of points can make it more legible. This can be observed in the faceting example below. 3.2.4 Shading Shading can be changed through the alpha = parameter. The first example below reproduces a plot using the same variables as the size example, except cty is mapped to alpha instead of size. The second examples uses the same variables as the first example from the color section, except it maps class to alpha instead of color. # using alpha to map a continuous variable ggplot(data = mpg) + geom_point(aes(x = displ, y = hwy, alpha = cty)) # using alpha to map a categorical variable ggplot(data = mpg) + geom_point(aes(x = displ, y = hwy, alpha = class)) ## Warning: Using alpha for a discrete variable is not advised. While shading can be mapped to a categorical variable, it is not recommended as it is better suited for continuous distinctions. 3.3 Faceting Faceting tells the computer to create separate graphs around a categorical variable using the specified geoms. This cannot be used with continuous variables. Faceting can be a powerful tool for observing differences between observations belonging to different categories and for creating effective time series graphs (covered in Section 4.7: Plotting Time Series). There are two function used to create facets: facet_wrap() and facet_grid(). facet_wrap() is used for faceting by a single variable, while facet_grid() is used to facet using two variables. ggplot(data = mpg) + geom_point(aes(x = displ, y = hwy)) + facet_wrap(~ class) # &#39;~ variable&#39; is crucial to the syntax of faceting ggplot(data = mpg) + geom_point(aes(x = displ, y = hwy), size = 0.5) + # size is changed for legibility facet_grid(drv ~ class) # in this case &#39;~&#39; separates the two variables you want to facet This feature of ggplot2 is very powerful as it allows a clear comparison of hwy and displ between different classes of cars. Trends within and between categories are able to be observed much more easily. This can be combined with other aesthetics to create visualizations that provide a great deal of information. Be cautious that you are not including too much information in one visualization. Sometimes it is best to produce individual facets manually for more in-depth analysis. 3.4 Geoms: Types of Plots This section will cover different types of geoms and how to use them in ggplot2. First, I will go over the five named graphs covered in Statistical Inference in Data Science: A Modern Dive into R and the Tidyverse: scatter plots, line graphs, histograms, box plots, and bar charts.65 Within each of these sections I will cover more unorthodox approaches to producing similar types of graphics. Many of these geoms can be combined to provide more information in each visualization as well. Each of these graphics has data which they are useful for; the best way to determine which one is best for your data is experimentation. 3.4.1 Scatter Plots So far we have extensively covered scatter plots in the earlier examples. To create a scatter plot, we use the geom_point() function demonstrated in examples above. Scatter plots are useful for visualizing the relationship between two continuous variables. They can be used for categorical variables as well, but convey much less information. For the examples in this section, I use the carat and price variables from the diamonds data set. diamonds |&gt; ggplot(aes(x = carat, y = price)) + geom_point(size = 0.25) I choose this example because it is a classic example of over-plotting.66 This means that there are too many points close together. In the plot above, this is so extreme there appear to be large black masses in much of the graph. I adjusted the size to try and mitigate this, but it only provided a slight improvement. One possible solutions is to use the alpha = parameter to adjust the transparency of the points. This is demonstrated in the code chunk below. This helps slightly but there is still a large amount of congestion. diamonds |&gt; ggplot(aes(x = carat, y = price)) + geom_point(alpha = 0.1, size = 0.25) The other method for mitigating the overlap of our data points is to jitter them. This means that each point is slightly randomly moved. This should be done with caution. While it does not modify the data itself, randomly jittering the points can produce a misleading visualization. This can be done through using geom_jitter() instead of geom_point().67 To specify how much jitter to add, you can use the width = and height = arguments.68 I do not recommend using this; it is never a light decision to modify data. If you do, make sure you note that they are jittered in the visualization. An alternative way to deal with over-plotting is to use an alternative geom that visualizes the density through color. These geoms, geom_bin2d() and geom_hex() mitigate the overlap of points through binning the observations. The code chunk below demonstrates how to use these two examples using the carat and price variables in the previous examples.69 diamonds |&gt; ggplot(aes(x = carat, y = price)) + geom_bin2d() diamonds |&gt; ggplot(aes(x = carat, y = price)) + geom_hex() 3.4.2 Line Graphs When producing a visualization, the variable on the x-axis is usually called the explanatory variable and the variable on the y-axis is usually called the dependent variable. Line graphs inherently imply that the points are sequential because they are connected visually. Therefore, line graphs are usually used when the explanatory variable (x-axis) is some unit of time. To create a line graph, instead of geom_point() use geom_line(). In the example below, I use the time_hour and temp variables in the weather data frame from nycflights13. To restrict the number of observations, I only use the weather from January 2013. weather |&gt; filter(month == 1) |&gt; ggplot(aes(x = time_hour, y = temp)) + geom_line() This produces a line graph that appears to have too many observations for the scale of the x-axis (by day). There are a few ways to mitigate this. You could only use the temperature from a certain time each day. This reduces the number of observations included in the graph making it much more legible. Another possible solutions would be to calculate an average for each day and use that instead. Both solutions are demonstrated in the code chunk below. The graph of the average temperatures produces a much better looking graph. This is where the data wrangling skills from the previous chapter really come in handy. weather |&gt; filter(month == 1 &amp; hour == 12) |&gt; ggplot(aes(x = time_hour, y = temp)) + geom_line() weather |&gt; filter(month == 1) |&gt; group_by(day) |&gt; summarize(avg_temp = mean(temp)) |&gt; # need to rename mean temp to a proper name for coding ggplot(aes(x = day, y = avg_temp)) + geom_line() 3.4.3 Histograms and Frequency Polygons A histogram is useful for visualizing the distribution of a variable. In a histogram, only the x-axis is assigned a variable. That variable is sectioned into bins. This means that all the observations are broken up into a number of groups, specified through the parameter bins =. When bins = is not specified, ggplot2 defaults to 30 bins. The more bins you use, the greater the level of detail in the histogram. The other way to set bins is to use the binwidth = argument. This specifies the range of each bin and makes the appropriate number of bins based on the specified size. In a histogram, the y-axis is usually the count of the observations that fit into each bin. The other option for the y-axis is the density of observations in each bin. This is a number between 0 and 1 that shows the percentage of observations within each bin. In the code chunk below, I use the price variable from the diamonds data set to demonstrate the geom_histogram() function. The first example shows a histogram using the default count stat with 100 bins. The second example shows a histogram using density instead of count and a bin width of 100. The geom_density() function, in the second example, adds the red line indicating the continuous density in addition to the bars. # histogram using the default count stat and bins = argument diamonds |&gt; ggplot(aes(x = price)) + geom_histogram(bins = 100) # histogram using density instead of count and the bidwidth = argument diamonds |&gt; ggplot(aes(x = price, y = after_stat(density))) + geom_histogram(binwidth = 100) + geom_density(color = &quot;red&quot;) # adds the red line indicating the density Frequency polygons are another useful way to show the distribution of a single variable. To create a frequency polygon in ggplot2, use the geom_freqpoly() function. When trying to observe the difference in the distribution of a variable between categories, frequency polygons offer a much better direct visual comparison. In the code chunk below, I demonstrate how to make a simple frequency polygon using the same variable as above and then use the cut variable to demonstrate how to use it to compare distributions between categories.70 diamonds |&gt; ggplot(aes(x = price)) + geom_freqpoly(bins = 100) diamonds |&gt; ggplot(aes(x = price, color = cut)) + geom_freqpoly(bins = 100) # this is an example from R for Data Science 71 3.4.4 Box Plots Box plots are another type of visualization that lends itself well to analyzing the distribution of observations across different categories. They are very useful for large data sets because each box plot looks the same regardless of the number of observations plotted. This feature is because box plots are all based off the five number summary: minimum, first quartile (25th percentile), median, third quartile (75th percentile), and maximum.72 To create a box plot, we use the geom_boxplot() function and usually two different variables, one continuous and one categorical. Typically, the continuous variable is mapped to the y-axis and the categorical one is mapped to the x-axis, though this can be reversed. The code chunk below demonstrates the syntax for making a box plot using the same variables as the histogram examples. diamonds |&gt; ggplot(aes(x = cut, y = price)) + geom_boxplot() While the uniform look of box plots regardless of the number of observations can be an advantage, some analysis may require a visualization that is more sensitive to the intricacies of the distribution. geom_violin() is a similar type of visualization that sacrifices the identification of outliers for a focus on where the observations fall. The code chunk below demonstrates geom_violin() using the same variables as the example above. diamonds |&gt; ggplot(aes(x = cut, y = price)) + geom_violin() 3.4.5 Bar Charts Bar charts are most useful for visualizing the distribution of a categorical variable.73 In ggplot2, the function for creating bar charts is geom_bar(). Notably, this function summarizes the data, automatically counting the number of observations in each category. If the data is summarized using the skills learned in Chapter 2, you should use the geom_col() function and specify both a x = and y = parameter. The code chunk below demonstrates both how to use the geom_bar() function, and how to generate the correct summary table and then use the geom_col() function. Both methods produce the same output and use the cut variable from the diamonds data set. diamonds |&gt; ggplot(aes(x = cut)) + geom_bar() diamonds |&gt; group_by(cut) |&gt; summarize(count = n()) |&gt; # run this code without the plotting to see the summary table ggplot(aes(x = cut, y = count)) + geom_col() The aesthetics of bar charts are also very useful for analyzing the relationship between two categorical variables.74 In the code chunk below, I generate the same graph using geom_bar() and map the color = and fill = aesthetics to the color variable in the diamonds data set. This allows for visual comparison of the number of observations that have a certain color between the different categories of cuts. diamonds |&gt; ggplot(aes(x = cut, color = color, fill = color)) + geom_bar() Bar charts have an argument called position = that allows you to change the layout of how each bar is arranged in the context of mapping another variable to color. The default position argument, shown in the previous example, is position = \"stack\". This means the different categories of color are stacked on top of each other. When position = stack, it can be hard to visually compare the number of observations of the color categories between cut categories. The first example below, using position = \"fill\", standardizes the size of each bar, allowing for direct comparison between categories. The second example, using position = \"dodge\", unstacks the bars so the exact level of each colored bar can be directly compared. diamonds |&gt; ggplot(aes(x = cut, color = color, fill = color)) + geom_bar(position = &quot;fill&quot;) diamonds |&gt; ggplot(aes(x = cut, color = color, fill = color)) + geom_bar(position = &quot;dodge&quot;) 3.4.6 Additional Geom Layers For reference below I have included images of the ggplot2 cheat sheet. This reference includes almost any possible geom you could want to use in creating a visualization. This resource is available online here. One important note is to avoid pie charts! Research has shown that they often lead to misinterpretations of data.75 Visually it is very hard to compare one piece of the pie to another due to the arrangement. Often, bar charts are a much better tool for these types of visualizations. 3.5 Modifying Data and Axes As discussed above, over-plotting is a common issue that can make well though-out graphs illegible. Faceting is one solution, but can lead to the individual facet graphs being to small to be of much use. In this section I will discuss other possible solutions to common over-plotting issues. 3.5.1 Filtering This may seem a little obvious, but a common and useful solution is to simply plot less data through filtering. Filtering data is covered in this section. In the Line Graphs section example, I use filtering to select only flights in January 2013. Piping is an important tool with these types of problems. Piping allows you to take a data frame, pipe it through any modifiers to wrangle it into the desired form, and then pipe the result straight into ggplot(). This removes the intermediary step of saving a modified version of your data before you create a new graph. If you are using the modified data multiple times, it is worth it to save it so you do not have to repeat code. An important part of data science is having a focused question. While looking at a very large data set in a meaningful way can be very important, when working with large data always ask yourself if you need all the data you have to answer your question. 3.5.2 xlim() and ylim() Another way to limit the scope of a visualization is to modify the axes. This can be useful when talking about a specific feature of the data and can also be done through filtering. For this example, I will use data from nycflights13. The code chunk below demonstrates the process of combining the seats variable from the planes data frame with the flights data frame. Refer to the chapter 2 for more information on the specifics of this. (flight_size &lt;- flights |&gt; # notice I selected the key (tailnum) and desired var (seats) from planes to join left_join(planes |&gt; select(tailnum, seats), by = &quot;tailnum&quot;)) |&gt; # this prevents unwanted data in the new data frame select(month, day, distance, dep_delay, seats) # select only variable I will use in visualization ## # A tibble: 336,776 × 5 ## month day distance dep_delay seats ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 1 1 1400 2 149 ## 2 1 1 1416 4 149 ## 3 1 1 1089 2 178 ## 4 1 1 1576 -1 200 ## 5 1 1 762 -6 178 ## 6 1 1 719 -4 191 ## 7 1 1 1065 -5 200 ## 8 1 1 229 -3 55 ## 9 1 1 944 -3 200 ## 10 1 1 733 -2 NA ## # ℹ 336,766 more rows After combining the data frame, I created below a scatter plot of the departure delay (dep_delay) and flight distance (distance) of all the planes that left NYC in January of 2013. In this scatter plot, I mapped the size aesthetic to the number of seats on the plane. The most obvious issue with this visualization is over-plotting. All of the points are clustered in the bottom left corner of the graph and leave a massive sections of blank space. (axes_example &lt;- flight_size |&gt; filter(month == 1 &amp; day == 1) |&gt; ggplot(aes(x = distance, y = dep_delay, size = seats)) + geom_point()) ## Warning: Removed 148 rows containing missing values (`geom_point()`). To mitigate this issue, I first modify the y-axis. I use the ylim(min, max) function for this. There does not appear to be any flights where dep_delay is greater than 400, so I limit the y axis from 0 to 400. The scale of the x-axis still appears to be causing over-plotting issues. axes_example + ylim(0,400) ## Warning: Removed 488 rows containing missing values (`geom_point()`). To limit the x-axis, I use the xlim(min, max) function. I choose to limit the x-axis to 3000, excluding one observation with a distance of 5000. The exclusion of data must always be noted, otherwise your visualization is misleading. In this case, it is such an extreme outlier and is only one observation so it has little effect on the visualization and is worth the added clarity. axes_example + ylim(0,400) + xlim(0,3000) ## Warning: Removed 489 rows containing missing values (`geom_point()`). This graph still suffers from a lack of clarity due to over-plotting but serves as a good example of how to experiment to find the best way to visualize data, while introducing these important functions. 3.6 Titles One of the wonderful features of ggplot2 is that it allows for complete customization of the titles. The variable names displayed on axes, while clear and concise for coding purposes, often do not provide enough information for academic work. It is important that axes titles are clear to the uninformed reader. Always provide units for axes titles and specify the time frame of your data in the header if applicable. Ideally you indicate the source on the graph as well. The titles are added through + labs(). This is demonstrated in the code chunk below. Look up the labs() function documentation for further options. example1 + labs(title = &quot;Scatter Plot of Highway Miles Per Gallon and Engine Size&quot;, subtitle = &quot;source: ggplot2&quot;, x = &quot;Engine Displacement (Liters)&quot;, y = &quot;Highway Miles Per Gallon&quot;) This example also demonstrates how to modify visualizations after they are saved within R. In this example, I call example1 above and use + labs() to modify titles. 3.7 Plotting Time Series This section covers the unique difficulties of properly plotting time series data. Time series data is any data that has a sequence through time. For this section we will use the economics data set included with ggplot2. This data set is presented in the code chunk below. When dealing with time series data the first important feature of the data set to identify is the time interval between observations. In our example, observations are taken on a monthly basis. The second important feature of a time series to identify is the span of the data in question. These data span from January of 1967 to April of 2015. economics ## # A tibble: 574 × 6 ## date pce pop psavert uempmed unemploy ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1967-07-01 507. 198712 12.6 4.5 2944 ## 2 1967-08-01 510. 198911 12.6 4.7 2945 ## 3 1967-09-01 516. 199113 11.9 4.6 2958 ## 4 1967-10-01 512. 199311 12.9 4.9 3143 ## 5 1967-11-01 517. 199498 12.8 4.7 3066 ## 6 1967-12-01 525. 199657 11.8 4.8 3018 ## 7 1968-01-01 531. 199808 11.7 5.1 2878 ## 8 1968-02-01 534. 199920 12.3 4.5 3001 ## 9 1968-03-01 544. 200056 11.7 4.1 2877 ## 10 1968-04-01 544 200208 12.3 4.6 2709 ## # ℹ 564 more rows It is crucially important that the variable indicating time is stored in a date object. Looking at the data frame above you can see that the date variable has the type &lt;date&gt;. This ensures that ggplot2 correctly recognizes that each value stands for a point in time and treats them properly. It also allows you to reference different components of the date_time object using function available through the lubridate package (included in the tidyverse). In the code chunk below I plot the median duration of unemployment in weeks (uempmed) over time (date). When plotting time series, I prefer to use geom_line(), to visually show the connected nature of the points, with geom_point() to indicate where each individual observation falls. economics |&gt; ggplot(aes(x = date, y = uempmed)) + geom_point(size = 0.5) + geom_line() The span of this data set causes the observations to be slightly too closely clustered together. In the code chunk below, I restricted the observations to be from 1980 to 1989 to demonstrate the effectiveness of this method on a smaller time frame. Notice how I used the year() function on the date object, allowing me to filter by year. economics |&gt; filter(year(date) &lt; 1990 &amp; year(date) &gt;= 1980) |&gt; ggplot(aes(x = date, y = uempmed)) + geom_point(size = 0.5) + geom_line() Returning to the original example in this section, faceting is the best method to use to improve the clarity of the plot of the complete time series without restricting the observations plotted. This also allows the trend within each year to be easily visually compared as each year has its own plot. economics |&gt; ggplot(aes(x = month(date), y = uempmed)) + geom_point(size = 0.5) + geom_line() + facet_wrap(~year(date)) 3.8 Saving and Showing Graphics For display, visualizations should be saved in the format of a .png. This format allows them to be easily references in a separate document if desired. To save a visualization, you should use the ggsave(\"filename\", plot = ) function. In the code chunk below, I save the first plot I made in this chapter by referencing its name in the plot = parameter. Crucially, the filename = parameter must have quotation marks around it and end with the proper file type. If the plot = parameter is not specified, then the function will automatically save the last plot you made. ggsave(&quot;example1.png&quot;, plot = example1) ## Saving 7 x 5 in image ggsave() can be used to save other file formats as well. Refer to the ggsave() documentation for more information and working examples. 3.9 Conclusion After reading this section, you should have a functional understanding of the grammar of graphics, the syntax of ggplot2, and how to make informative and functional data visualizations for basic statistics. Throughout this chapter, I combined resources from a variety of free, online resources. These resources go into greater detail on the technical side of these topics, and provide more working examples. The purpose of this chapter is to quickly give a foundation in the basics of these topics. If something does not make sense, or your you would like to know more do not hesitate to refer to these resources (available in references). References "],["overview-of-additional-resources.html", "Overview of Additional Resources", " Overview of Additional Resources Below is a list of all resources used in compiling this guide. They all have different strengths and provide useful insights in how to effectively use R. R for Data Science76 seminal overview of how to use R goes into further depth and provides many more examples and exercises on most topics covered Data Wrangling77 good information on data wrangling, scraping, and interacting with APIs including tidycensus Analyzing US Census Data: Methods, Maps, and Models in R78 best information on using tidycensus and dealing with census data Statistical Inference via Data Science: A ModernDive into r and the Tidyverse79 great information linking statistical knowledge with the tidyverse lots of information on how to produce effective visualizations Ggplot2: Elegant Graphics for Data Analysis80 best book for in-depth information on all the possibilities available through ggplot2 bookdown.org center for textbooks such as this one produced using the bookdown package links to books on anything you might want to do using R "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
